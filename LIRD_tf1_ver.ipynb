{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIRD_tf1_ver",
      "provenance": [],
      "collapsed_sections": [
        "gwoaes5UyJJS",
        "gfGFFQeZyQfG",
        "ZGvAXnJayWjt",
        "3-rEdckqygGY",
        "lVAPvO0Nyyy3",
        "KNP3jdofyh7M"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwan27/thebest52/blob/master/LIRD_tf1_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VCoNiElLnK4"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx42q6XFNbAe",
        "outputId": "e2114868-7a06-4d69-b18d-28d3eeafc6a4"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 64.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 58.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.35.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=b7104b24f6e3c5b4dfbbf423af5871d91caf97071b186f67df74126ccaed3d67\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKmjjI_7qfaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abe9f9e-ed5a-412d-e32f-af57ca94db2d"
      },
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import csv\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras.backend as K\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwoaes5UyJJS"
      },
      "source": [
        "# MovieLens 100k Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2H9eM4YuOy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a523b1-eb93-449c-b1ef-725e39a6e938"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-30 12:52:58--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  4.71MB/s    in 1.0s    \n",
            "\n",
            "2020-11-30 12:52:59 (4.71 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "a9GqztJLS4AJ",
        "outputId": "93c14607-98d1-4dc3-b7f7-c70ad13b02e2"
      },
      "source": [
        "data = pd.read_csv('ml-100k/u.data', sep='\\t', \n",
        "                    names=['userId', 'itemId', 'rating', 'timestamp'])\n",
        "# movie_titles = pd.read_csv(itempath, sep='|', names=['itemId', 'itemName'],\n",
        "#                         usecols=range(2), encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-32b46e47d8d7>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    #                         usecols=range(2), encoding='latin-1')\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yST4dc3wtm2T"
      },
      "source": [
        "class DataGenerator():\n",
        "  def __init__(self, datapath, itempath):\n",
        "    '''\n",
        "    Load data from the DB MovieLens\n",
        "    List the users and the items\n",
        "    List all the users historic\n",
        "    '''\n",
        "    self.data  = self.load_datas(datapath, itempath)\n",
        "    self.users = self.data['userId'].unique()   #list of all users\n",
        "    self.items = self.data['itemId'].unique()   #list of all items\n",
        "    self.histo = self.gen_histo()\n",
        "    self.train = []\n",
        "    self.test  = []\n",
        "\n",
        "  def load_datas(self, datapath, itempath):\n",
        "    '''\n",
        "    Load the data and merge the name of each movie. \n",
        "    A row corresponds to a rate given by a user to a movie.\n",
        "\n",
        "     Parameters\n",
        "    ----------\n",
        "    datapath :  string\n",
        "                path to the data 100k MovieLens\n",
        "                contains usersId;itemId;rating \n",
        "    itempath :  string\n",
        "                path to the data 100k MovieLens\n",
        "                contains itemId;itemName\n",
        "     Returns\n",
        "    -------\n",
        "    result :    DataFrame\n",
        "                Contains all the ratings \n",
        "    '''\n",
        "    data = pd.read_csv(datapath, sep='\\t', \n",
        "                       names=['userId', 'itemId', 'rating', 'timestamp'])\n",
        "    movie_titles = pd.read_csv(itempath, sep='|', names=['itemId', 'itemName'],\n",
        "                           usecols=range(2), encoding='latin-1')\n",
        "    return data.merge(movie_titles,on='itemId', how='left')\n",
        "\n",
        "\n",
        "  def gen_histo(self):\n",
        "    '''\n",
        "    Group all rates given by users and store them from older to most recent.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    result :    List(DataFrame)\n",
        "                List of the historic for each user\n",
        "    '''\n",
        "    historic_users = []\n",
        "    for i, u in enumerate(self.users):\n",
        "      temp = self.data[self.data['userId'] == u]\n",
        "      temp = temp.sort_values('timestamp').reset_index()\n",
        "      temp.drop('index', axis=1, inplace=True)\n",
        "      historic_users.append(temp)\n",
        "    return historic_users\n",
        "\n",
        "  def sample_histo(self, user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
        "    '''\n",
        "    For a given historic, make one or multiple sampling.\n",
        "    If no optional argument given for nb_states and nb_actions, then the sampling\n",
        "    is random and each sample can have differents size for action and state.\n",
        "    To normalize sampling we need to give list of the numbers of states and actions\n",
        "    to be sampled.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    user_histo :  DataFrame\n",
        "                      historic of user\n",
        "    delimiter :       string, optional\n",
        "                      delimiter for the csv\n",
        "    action_ratio :    float, optional\n",
        "                      ratio form which movies in history will be selected\n",
        "    max_samp_by_user: int, optional\n",
        "                      Nulber max of sample to make by user\n",
        "    max_state :       int, optional\n",
        "                      Number max of movies to take for the 'state' column\n",
        "    max_action :      int, optional\n",
        "                      Number max of movies to take for the 'action' action\n",
        "    nb_states :       array(int), optional\n",
        "                      Numbers of movies to be taken for each sample made on user's historic\n",
        "    nb_actions :      array(int), optional\n",
        "                      Numbers of rating to be taken for each sample made on user's historic\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    states :         List(String)\n",
        "                     All the states sampled, format of a sample: itemId&rating\n",
        "    actions :        List(String)\n",
        "                     All the actions sampled, format of a sample: itemId&rating\n",
        "  \n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    States must be before(timestamp<) the actions.\n",
        "    If given, size of nb_states is the numbller of sample by user\n",
        "    sizes of nb_states and nb_actions must be equals\n",
        "    '''\n",
        "\n",
        "    n = len(user_histo)\n",
        "    sep = int(action_ratio * n)\n",
        "    nb_sample = random.randint(1, max_samp_by_user)\n",
        "    if not nb_states:\n",
        "      nb_states = [min(random.randint(1, sep), max_state) for i in range(nb_sample)]\n",
        "    if not nb_actions:\n",
        "      nb_actions = [min(random.randint(1, n - sep), max_action) for i in range(nb_sample)]\n",
        "    assert len(nb_states) == len(nb_actions), 'Given array must have the same size'\n",
        "    \n",
        "    states  = []\n",
        "    actions = []\n",
        "    # SELECT SAMPLES IN HISTO\n",
        "    for i in range(len(nb_states)):\n",
        "      sample_states = user_histo.iloc[0:sep].sample(nb_states[i])\n",
        "      sample_actions = user_histo.iloc[-(n - sep):].sample(nb_actions[i])\n",
        "      \n",
        "      sample_state =  []\n",
        "      sample_action = []\n",
        "      for j in range(nb_states[i]):\n",
        "        row   = sample_states.iloc[j]\n",
        "        # FORMAT STATE\n",
        "        state = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "        sample_state.append(state)\n",
        "      \n",
        "      for j in range(nb_actions[i]):\n",
        "        row    = sample_actions.iloc[j]\n",
        "        # FORMAT ACTION\n",
        "        action = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "        sample_action.append(action)\n",
        "\n",
        "      states.append(sample_state)\n",
        "      actions.append(sample_action)\n",
        "    return states, actions\n",
        "\n",
        "  def gen_train_test(self, test_ratio, seed=None):\n",
        "    '''\n",
        "    Shuffle the historic of users and separate it in a train and a test set.\n",
        "    Store the ids for each set.\n",
        "    An user can't be in both set.\n",
        "\n",
        "     Parameters\n",
        "    ----------\n",
        "    test_ratio :  float\n",
        "                  Ratio to control the sizes of the sets\n",
        "    seed       :  float\n",
        "                  Seed on the shuffle\n",
        "    '''\n",
        "    n = len(self.histo)\n",
        "\n",
        "    if seed is not None:\n",
        "      random.Random(seed).shuffle(self.histo)\n",
        "    else:\n",
        "      random.shuffle(self.histo)\n",
        "\n",
        "    self.train = self.histo[:int((test_ratio * n))]\n",
        "    self.test  = self.histo[int((test_ratio * n)):]\n",
        "    self.user_train = [h.iloc[0,0] for h in self.train]\n",
        "    self.user_test  = [h.iloc[0,0] for h in self.test]\n",
        "    \n",
        "\n",
        "  def write_csv(self, filename, histo_to_write, delimiter=';', action_ratio=0.8, max_samp_by_user=5, max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
        "    '''\n",
        "    From  a given historic, create a csv file with the format:\n",
        "    columns : state;action_reward;n_state\n",
        "    rows    : itemid&rating1 | itemid&rating2 | ... ; itemid&rating3 | ... | itemid&rating4; itemid&rating1 | itemid&rating2 | itemid&rating3 | ... | item&rating4\n",
        "    at filename location.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename :        string\n",
        "                      path to the file to be produced\n",
        "    histo_to_write :  List(DataFrame)\n",
        "                      List of the historic for each user\n",
        "    delimiter :       string, optional\n",
        "                      delimiter for the csv\n",
        "    action_ratio :    float, optional\n",
        "                      ratio form which movies in history will be selected\n",
        "    max_samp_by_user: int, optional\n",
        "                      Nulber max of sample to make by user\n",
        "    max_state :       int, optional\n",
        "                      Number max of movies to take for the 'state' column\n",
        "    max_action :      int, optional\n",
        "                      Number max of movies to take for the 'action' action\n",
        "    nb_states :       array(int), optional\n",
        "                      Numbers of movies to be taken for each sample made on user's historic\n",
        "    nb_actions :      array(int), optional\n",
        "                      Numbers of rating to be taken for each sample made on user's historic\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    if given, size of nb_states is the numbller of sample by user\n",
        "    sizes of nb_states and nb_actions must be equals\n",
        "\n",
        "    '''\n",
        "    with open(filename, mode='w') as file:\n",
        "      f_writer = csv.writer(file, delimiter=delimiter)\n",
        "      f_writer.writerow(['state', 'action_reward', 'n_state'])\n",
        "      for user_histo in histo_to_write:\n",
        "        states, actions = self.sample_histo(user_histo, action_ratio, max_samp_by_user, max_state, max_action, nb_states, nb_actions)\n",
        "        for i in range(len(states)):\n",
        "          # FORMAT STATE\n",
        "          state_str   = '|'.join(states[i])\n",
        "          # FORMAT ACTION\n",
        "          action_str  = '|'.join(actions[i])\n",
        "          # FORMAT N_STATE\n",
        "          n_state_str = state_str + '|' + action_str\n",
        "          f_writer.writerow([state_str, action_str, n_state_str])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfGFFQeZyQfG"
      },
      "source": [
        "# Movies Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578-inzm24sj"
      },
      "source": [
        "class EmbeddingsGenerator:\n",
        "  def  __init__(self, train_users, data):\n",
        "    self.train_users = train_users\n",
        "\n",
        "    #preprocess\n",
        "    self.data = data.sort_values(by=['timestamp'])\n",
        "    #make them start at 0\n",
        "    self.data['userId'] = self.data['userId'] - 1\n",
        "    self.data['itemId'] = self.data['itemId'] - 1\n",
        "    self.user_count = self.data['userId'].max() + 1\n",
        "    self.movie_count = self.data['itemId'].max() + 1\n",
        "    self.user_movies = {} #list of rated movies by each user\n",
        "    for userId in range(self.user_count):\n",
        "      self.user_movies[userId] = self.data[self.data.userId == userId]['itemId'].tolist()\n",
        "    self.m = self.model()\n",
        "\n",
        "  def model(self, hidden_layer_size=100):\n",
        "    m = Sequential()\n",
        "    m.add(Dense(hidden_layer_size, input_shape=(1, self.movie_count)))\n",
        "    m.add(Dropout(0.2))\n",
        "    m.add(Dense(self.movie_count, activation='softmax'))\n",
        "    m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "  \n",
        "  def generate_input(self, user_id):\n",
        "    '''\n",
        "    Returns a context and a target for the user_id\n",
        "    context: user's history with one random movie removed\n",
        "    target: id of random removed movie\n",
        "    '''\n",
        "    user_movies_count = len(self.user_movies[user_id])\n",
        "    #picking random movie\n",
        "    random_index = np.random.randint(0, user_movies_count-1) # -1 avoids taking the last movie\n",
        "    #setting target\n",
        "    target = np.zeros((1, self.movie_count))\n",
        "    target[0][self.user_movies[user_id][random_index]] = 1\n",
        "    #setting context\n",
        "    context = np.zeros((1, self.movie_count))\n",
        "    context[0][self.user_movies[user_id][:random_index] + self.user_movies[user_id][random_index+1:]] = 1\n",
        "    return context, target\n",
        "\n",
        "  def train(self, nb_epochs = 300, batch_size = 10000):\n",
        "    '''\n",
        "    Trains the model from train_users's history\n",
        "    '''\n",
        "    for i in range(nb_epochs):\n",
        "      print('%d/%d' % (i+1, nb_epochs))\n",
        "      batch = [self.generate_input(user_id=np.random.choice(self.train_users) - 1) for _ in range(batch_size)]\n",
        "      X_train = np.array([b[0] for b in batch])\n",
        "      y_train = np.array([b[1] for b in batch])\n",
        "      self.m.fit(X_train, y_train, epochs=1, validation_split=0.5)\n",
        "\n",
        "  def test(self, test_users, batch_size = 100000):\n",
        "    '''\n",
        "    Returns [loss, accuracy] on the test set\n",
        "    '''\n",
        "    batch_test = [self.generate_input(user_id=np.random.choice(test_users) - 1) for _ in range(batch_size)]\n",
        "    X_test = np.array([b[0] for b in batch_test])\n",
        "    y_test = np.array([b[1] for b in batch_test])\n",
        "    return self.m.evaluate(X_test, y_test)\n",
        "\n",
        "  def save_embeddings(self, file_name):\n",
        "    '''\n",
        "    Generates a csv file containg the vector embedding for each movie.\n",
        "    '''\n",
        "    inp = self.m.input                                           # input placeholder\n",
        "    outputs = [layer.output for layer in self.m.layers]          # all layer outputs\n",
        "    functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
        "\n",
        "    #append embeddings to vectors\n",
        "    vectors = []\n",
        "    for movie_id in range(self.movie_count):\n",
        "      movie = np.zeros((1, 1, self.movie_count))\n",
        "      movie[0][0][movie_id] = 1\n",
        "      layer_outs = functor([movie])\n",
        "      vector = [str(v) for v in layer_outs[0][0][0]]\n",
        "      vector = '|'.join(vector)\n",
        "      vectors.append([movie_id, vector])\n",
        "\n",
        "    #saves as a csv file\n",
        "    embeddings = pd.DataFrame(vectors, columns=['item_id', 'vectors']).astype({'item_id': 'int32'})\n",
        "    embeddings.to_csv(file_name, sep=';', index=False)\n",
        "    files.download(file_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpKB5xexLvSI"
      },
      "source": [
        "class Embeddings:\n",
        "  def __init__(self, item_embeddings):\n",
        "    self.item_embeddings = item_embeddings\n",
        "  \n",
        "  def size(self):\n",
        "    return self.item_embeddings.shape[1]\n",
        "  \n",
        "  def get_embedding_vector(self):\n",
        "    return self.item_embeddings\n",
        "  \n",
        "  def get_embedding(self, item_index):\n",
        "    return self.item_embeddings[item_index]\n",
        "\n",
        "  def embed(self, item_list):\n",
        "    return np.array([self.get_embedding(item) for item in item_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AolIkmf0LWZP"
      },
      "source": [
        "def read_file(data_path):\n",
        "  ''' Load data from train.csv or test.csv. '''\n",
        "\n",
        "  data = pd.read_csv(data_path, sep=';')\n",
        "  for col in ['state', 'n_state', 'action_reward']:\n",
        "    data[col] = [np.array([[np.int(k) for k in ee.split('&')] for ee in e.split('|')]) for e in data[col]]\n",
        "  for col in ['state', 'n_state']:\n",
        "    data[col] = [np.array([e[0] for e in l]) for l in data[col]]\n",
        "\n",
        "  data['action'] = [[e[0] for e in l] for l in data['action_reward']]\n",
        "  data['reward'] = [tuple(e[1] for e in l) for l in data['action_reward']]\n",
        "  data.drop(columns=['action_reward'], inplace=True)\n",
        "\n",
        "  return data\n",
        "\n",
        "def read_embeddings(embeddings_path):\n",
        "  ''' Load embeddings (a vector for each item). '''\n",
        "  \n",
        "  embeddings = pd.read_csv(embeddings_path, sep=';')\n",
        "\n",
        "  return np.array([[np.float64(k) for k in e.split('|')]\n",
        "                   for e in embeddings['vectors']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGvAXnJayWjt"
      },
      "source": [
        "# Environment/Simulator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H00n2XsouByw"
      },
      "source": [
        "class Environment():\n",
        "  def __init__(self, data, embeddings, alpha, gamma, fixed_length):\n",
        "    self.embeddings = embeddings\n",
        "\n",
        "    self.embedded_data = pd.DataFrame()\n",
        "    self.embedded_data['state'] = [np.array([embeddings.get_embedding(item_id) \n",
        "      for item_id in row['state']]) for _, row in data.iterrows()]\n",
        "    self.embedded_data['action'] = [np.array([embeddings.get_embedding(item_id) \n",
        "      for item_id in row['action']]) for _, row in data.iterrows()]\n",
        "    self.embedded_data['reward'] = data['reward']\n",
        "\n",
        "    self.alpha = alpha # α (alpha) in Equation (1)\n",
        "    self.gamma = gamma # Γ (Gamma) in Equation (4)\n",
        "    self.fixed_length = fixed_length\n",
        "    self.current_state = self.reset()\n",
        "    self.groups = self.get_groups()\n",
        "\n",
        "  def reset(self):\n",
        "    self.init_state = self.embedded_data['state'].sample(1).values[0]\n",
        "    return self.init_state\n",
        "\n",
        "  def step(self, actions):\n",
        "    '''\n",
        "    Compute reward and update state.\n",
        "    Args:\n",
        "      actions: embedded chosen items.\n",
        "    Returns:\n",
        "      cumulated_reward: overall reward.\n",
        "      current_state: updated state.\n",
        "    '''\n",
        "\n",
        "    # '18: Compute overall reward r_t according to Equation (4)'\n",
        "    simulated_rewards, cumulated_reward = self.simulate_rewards(self.current_state.reshape((1, -1)), actions.reshape((1, -1)))\n",
        "\n",
        "    # '11: Set s_t+1 = s_t' <=> self.current_state = self.current_state\n",
        "\n",
        "    for k in range(len(simulated_rewards)): # '12: for k = 1, K do'\n",
        "      if simulated_rewards[k] > 0: # '13: if r_t^k > 0 then'\n",
        "        # '14: Add a_t^k to the end of s_t+1'\n",
        "        self.current_state = np.append(self.current_state, [actions[k]], axis=0)\n",
        "        if self.fixed_length: # '15: Remove the first item of s_t+1'\n",
        "          self.current_state = np.delete(self.current_state, 0, axis=0)\n",
        "\n",
        "    return cumulated_reward, self.current_state\n",
        "\n",
        "  def get_groups(self):\n",
        "    ''' Calculate average state/action value for each group. Equation (3). '''\n",
        "\n",
        "    groups = []\n",
        "    for rewards, group in self.embedded_data.groupby(['reward']):\n",
        "      size = group.shape[0]\n",
        "      states = np.array(list(group['state'].values))\n",
        "      actions = np.array(list(group['action'].values))\n",
        "      groups.append({\n",
        "        'size': size, # N_x in article\n",
        "        'rewards': rewards, # U_x in article (combination of rewards)\n",
        "        'average state': (np.sum(states / np.linalg.norm(states, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)), # s_x^-\n",
        "        'average action': (np.sum(actions / np.linalg.norm(actions, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)) # a_x^-\n",
        "      })\n",
        "    return groups\n",
        "\n",
        "  def simulate_rewards(self, current_state, chosen_actions, reward_type='grouped cosine'):\n",
        "    '''\n",
        "    Calculate simulated rewards.\n",
        "    Args:\n",
        "      current_state: history, list of embedded items.\n",
        "      chosen_actions: embedded chosen items.\n",
        "      reward_type: from ['normal', 'grouped average', 'grouped cosine'].\n",
        "    Returns:\n",
        "      returned_rewards: most probable rewards.\n",
        "      cumulated_reward: probability weighted rewards.\n",
        "    '''\n",
        "\n",
        "    # Equation (1)\n",
        "    def cosine_state_action(s_t, a_t, s_i, a_i):\n",
        "      cosine_state = np.dot(s_t, s_i.T) / (np.linalg.norm(s_t, 2) * np.linalg.norm(s_i, 2))\n",
        "      cosine_action = np.dot(a_t, a_i.T) / (np.linalg.norm(a_t, 2) * np.linalg.norm(a_i, 2))\n",
        "      return (self.alpha * cosine_state + (1 - self.alpha) * cosine_action).reshape((1,))\n",
        "\n",
        "    if reward_type == 'normal':\n",
        "      # Calculate simulated reward in normal way: Equation (2)\n",
        "      probabilities = [cosine_state_action(current_state, chosen_actions, row['state'], row['action'])\n",
        "        for _, row in self.embedded_data.iterrows()]\n",
        "    elif reward_type == 'grouped average':\n",
        "      # Calculate simulated reward by grouped average: Equation (3)\n",
        "      probabilities = np.array([g['size'] for g in self.groups]) *\\\n",
        "        [(self.alpha * (np.dot(current_state, g['average state'].T) / np.linalg.norm(current_state, 2))\\\n",
        "        + (1 - self.alpha) * (np.dot(chosen_actions, g['average action'].T) / np.linalg.norm(chosen_actions, 2)))\n",
        "        for g in self.groups]\n",
        "    elif reward_type == 'grouped cosine':\n",
        "      # Calculate simulated reward by grouped cosine: Equations (1) and (3)\n",
        "      probabilities = [cosine_state_action(current_state, chosen_actions, g['average state'], g['average action'])\n",
        "        for g in self.groups]\n",
        "\n",
        "    # Normalize (sum to 1)\n",
        "    probabilities = np.array(probabilities) / sum(probabilities)\n",
        "\n",
        "    # Get most probable rewards\n",
        "    if reward_type == 'normal':\n",
        "      returned_rewards = self.embedded_data.iloc[np.argmax(probabilities)]['reward']\n",
        "    elif reward_type in ['grouped average', 'grouped cosine']:\n",
        "      returned_rewards = self.groups[np.argmax(probabilities)]['rewards']\n",
        "\n",
        "    # Equation (4)\n",
        "    def overall_reward(rewards, gamma):\n",
        "      return np.sum([gamma**k * reward for k, reward in enumerate(rewards)])\n",
        "\n",
        "    if reward_type in ['normal', 'grouped average']:\n",
        "      # Get cumulated reward: Equation (4)\n",
        "      cumulated_reward = overall_reward(returned_rewards, self.gamma)\n",
        "    elif reward_type == 'grouped cosine':\n",
        "      # Get probability weighted cumulated reward\n",
        "      cumulated_reward = np.sum([p * overall_reward(g['rewards'], self.gamma)\n",
        "        for p, g in zip(probabilities, self.groups)])\n",
        "\n",
        "    return returned_rewards, cumulated_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rEdckqygGY"
      },
      "source": [
        "# Actor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YK3aSNaTouH"
      },
      "source": [
        "class Actor():\n",
        "  ''' Policy function approximator. '''\n",
        "  \n",
        "  def __init__(self, sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embedding_size, tau, learning_rate, scope='actor'):\n",
        "    self.sess = sess\n",
        "    self.state_space_size = state_space_size\n",
        "    self.action_space_size = action_space_size\n",
        "    self.batch_size = batch_size\n",
        "    self.ra_length = ra_length\n",
        "    self.history_length = history_length\n",
        "    self.embedding_size = embedding_size\n",
        "    self.tau = tau\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scope = scope\n",
        "\n",
        "    with tf.variable_scope(self.scope):\n",
        "      # Build Actor network\n",
        "      self.action_weights, self.state, self.sequence_length = self._build_net('estimator_actor')\n",
        "      self.network_params = tf.trainable_variables()\n",
        "\n",
        "      # Build target Actor network\n",
        "      self.target_action_weights, self.target_state, self.target_sequence_length = self._build_net('target_actor')\n",
        "      self.target_network_params = tf.trainable_variables()[len(self.network_params):] # TODO: why sublist [len(x):]? Maybe because its equal to network_params + target_network_params\n",
        "\n",
        "      # Initialize target network weights with network weights (θ^π′ ← θ^π)\n",
        "      self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
        "        for i in range(len(self.target_network_params))]\n",
        "        \n",
        "      # Update target network weights (θ^π′ ← τθ^π + (1 − τ)θ^π′)\n",
        "      self.update_target_network_params = [self.target_network_params[i].assign(\n",
        "        tf.multiply(self.tau, self.network_params[i]) +\n",
        "        tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      # Gradient computation from Critic's action_gradients\n",
        "      self.action_gradients = tf.placeholder(tf.float32, [None, self.action_space_size])\n",
        "      gradients = tf.gradients(tf.reshape(self.action_weights, [self.batch_size, self.action_space_size], name='42222222222'),\n",
        "                               self.network_params,\n",
        "                               self.action_gradients)\n",
        "      params_gradients = list(map(lambda x: tf.div(x, self.batch_size * self.action_space_size), gradients))\n",
        "      \n",
        "      # Compute ∇_a.Q(s, a|θ^µ).∇_θ^π.f_θ^π(s)\n",
        "      self.optimizer = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(\n",
        "          zip(params_gradients, self.network_params))\n",
        "\n",
        "  def _build_net(self, scope):\n",
        "    ''' Build the (target) Actor network. '''\n",
        "\n",
        "    def gather_last_output(data, seq_lens):\n",
        "      def cli_value(x, v):\n",
        "        y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
        "        x = tf.cast(x, tf.int64)\n",
        "        return tf.where(tf.greater(x, y), x, y)\n",
        "\n",
        "      batch_range = tf.range(tf.cast(tf.shape(data)[0], dtype=tf.int64), dtype=tf.int64)\n",
        "      tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
        "      indices = tf.stack([batch_range, tmp_end], axis=1)\n",
        "      return tf.gather_nd(data, indices)\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "      # Inputs: current state, sequence_length\n",
        "      # Outputs: action weights to compute the score Equation (6)\n",
        "      state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
        "      state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
        "      sequence_length = tf.placeholder(tf.int32, [None], 'sequence_length')\n",
        "      cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
        "                                    activation=tf.nn.relu,\n",
        "                                    kernel_initializer=tf.initializers.random_normal(),\n",
        "                                    bias_initializer=tf.zeros_initializer())\n",
        "      outputs, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
        "      last_output = gather_last_output(outputs, sequence_length) # TODO: replace by h\n",
        "      x = tf.keras.layers.Dense(self.ra_length * self.embedding_size)(last_output)\n",
        "      action_weights = tf.reshape(x, [-1, self.ra_length, self.embedding_size])\n",
        "\n",
        "    return action_weights, state, sequence_length\n",
        "\n",
        "  def train(self, state, sequence_length, action_gradients):\n",
        "    '''  Compute ∇_a.Q(s, a|θ^µ).∇_θ^π.f_θ^π(s). '''\n",
        "    self.sess.run(self.optimizer,\n",
        "                  feed_dict={\n",
        "                      self.state: state,\n",
        "                      self.sequence_length: sequence_length,\n",
        "                      self.action_gradients: action_gradients})\n",
        "\n",
        "  def predict(self, state, sequence_length):\n",
        "    return self.sess.run(self.action_weights,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.sequence_length: sequence_length})\n",
        "\n",
        "  def predict_target(self, state, sequence_length):\n",
        "    return self.sess.run(self.target_action_weights,\n",
        "                         feed_dict={\n",
        "                             self.target_state: state,\n",
        "                             self.target_sequence_length: sequence_length})\n",
        "\n",
        "  def init_target_network(self):\n",
        "    self.sess.run(self.init_target_network_params)\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.sess.run(self.update_target_network_params)\n",
        "    \n",
        "  def get_recommendation_list(self, ra_length, noisy_state, embeddings, target=False):\n",
        "    '''\n",
        "    Algorithm 2\n",
        "    Args:\n",
        "      ra_length: length of the recommendation list.\n",
        "      noisy_state: current/remembered environment state with noise.\n",
        "      embeddings: Embeddings object.\n",
        "      target: boolean to use Actor's network or target network.\n",
        "    Returns:\n",
        "      Recommendation List: list of embedded items as future actions.\n",
        "    '''\n",
        "\n",
        "    def get_score(weights, embedding, batch_size):\n",
        "      '''\n",
        "      Equation (6)\n",
        "      Args:\n",
        "        weights: w_t^k shape=(embedding_size,).\n",
        "        embedding: e_i shape=(embedding_size,).\n",
        "      Returns:\n",
        "        score of the item i: score_i=w_t^k.e_i^T shape=(1,).\n",
        "      '''\n",
        "      ret = np.dot(weights, embedding.T)\n",
        "      return ret\n",
        "\n",
        "    batch_size = noisy_state.shape[0]\n",
        "\n",
        "    # '1: Generate w_t = {w_t^1, ..., w_t^K} according to Equation (5)'\n",
        "    method = self.predict_target if target else self.predict\n",
        "    weights = method(noisy_state, [ra_length] * batch_size)\n",
        "\n",
        "    # '3: Score items in I according to Equation (6)'\n",
        "    scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n",
        "      for embedding in embeddings.get_embedding_vector()]\n",
        "      for k in range(ra_length)]\n",
        "      for i in range(batch_size)])\n",
        "\n",
        "    # '8: return a_t'\n",
        "    return np.array([[embeddings.get_embedding(np.argmax(scores[i][k]))\n",
        "      for k in range(ra_length)]\n",
        "      for i in range(batch_size)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVAPvO0Nyyy3"
      },
      "source": [
        "# Critic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj3yEhnqy0Iy"
      },
      "source": [
        "class Critic():\n",
        "  ''' Value function approximator. '''\n",
        "  \n",
        "  def __init__(self, sess, state_space_size, action_space_size, history_length, embedding_size, tau, learning_rate, scope='critic'):\n",
        "    self.sess = sess\n",
        "    self.state_space_size = state_space_size\n",
        "    self.action_space_size = action_space_size\n",
        "    self.history_length = history_length\n",
        "    self.embedding_size = embedding_size\n",
        "    self.tau = tau\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scope = scope\n",
        "\n",
        "    with tf.variable_scope(self.scope):\n",
        "      # Build Critic network\n",
        "      self.critic_Q_value, self.state, self.action, self.sequence_length = self._build_net('estimator_critic')\n",
        "      self.network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='estimator_critic')\n",
        "\n",
        "      # Build target Critic network\n",
        "      self.target_Q_value, self.target_state, self.target_action, self.target_sequence_length = self._build_net('target_critic')\n",
        "      self.target_network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_critic')\n",
        "\n",
        "      # Initialize target network weights with network weights (θ^µ′ ← θ^µ)\n",
        "      self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      # Update target network weights (θ^µ′ ← τθ^µ + (1 − τ)θ^µ′)\n",
        "      self.update_target_network_params = [self.target_network_params[i].assign(\n",
        "        tf.multiply(self.tau, self.network_params[i]) +\n",
        "        tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      # Minimize MSE between Critic's and target Critic's outputed Q-values\n",
        "      self.expected_reward = tf.placeholder(tf.float32, [None, 1])\n",
        "      self.loss = tf.reduce_mean(tf.squared_difference(self.expected_reward, self.critic_Q_value))\n",
        "      self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
        "\n",
        "      # Compute ∇_a.Q(s, a|θ^µ)\n",
        "      self.action_gradients = tf.gradients(self.critic_Q_value, self.action)\n",
        "\n",
        "  def _build_net(self, scope):\n",
        "    ''' Build the (target) Critic network. '''\n",
        "\n",
        "    def gather_last_output(data, seq_lens):\n",
        "      def cli_value(x, v):\n",
        "        y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
        "        return tf.where(tf.greater(x, y), x, y)\n",
        "\n",
        "      this_range = tf.range(tf.cast(tf.shape(seq_lens)[0], dtype=tf.int64), dtype=tf.int64)\n",
        "      tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
        "      indices = tf.stack([this_range, tmp_end], axis=1)\n",
        "      return tf.gather_nd(data, indices)\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "      # Inputs: current state, current action\n",
        "      # Outputs: predicted Q-value\n",
        "      state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
        "      state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
        "      action = tf.placeholder(tf.float32, [None, self.action_space_size], 'action')\n",
        "      sequence_length = tf.placeholder(tf.int64, [None], name='critic_sequence_length')\n",
        "      cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n",
        "                                    activation=tf.nn.relu,\n",
        "                                    kernel_initializer=tf.initializers.random_normal(),\n",
        "                                    bias_initializer=tf.zeros_initializer())\n",
        "      predicted_state, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
        "      predicted_state = gather_last_output(predicted_state, sequence_length)\n",
        "\n",
        "      inputs = tf.concat([predicted_state, action], axis=-1)\n",
        "      layer1 = tf.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
        "      layer2 = tf.layers.Dense(16, activation=tf.nn.relu)(layer1)\n",
        "      critic_Q_value = tf.layers.Dense(1)(layer2)\n",
        "      return critic_Q_value, state, action, sequence_length\n",
        "\n",
        "  def train(self, state, action, sequence_length, expected_reward):\n",
        "    ''' Minimize MSE between expected reward and target Critic's Q-value. '''\n",
        "    return self.sess.run([self.critic_Q_value, self.loss, self.optimizer],\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length,\n",
        "                             self.expected_reward: expected_reward})\n",
        "\n",
        "  def predict(self, state, action, sequence_length):\n",
        "    ''' Returns Critic's predicted Q-value. '''\n",
        "    return self.sess.run(self.critic_Q_value,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length})\n",
        "\n",
        "  def predict_target(self, state, action, sequence_length):\n",
        "    ''' Returns target Critic's predicted Q-value. '''\n",
        "    return self.sess.run(self.target_Q_value,\n",
        "                         feed_dict={\n",
        "                             self.target_state: state,\n",
        "                             self.target_action: action,\n",
        "                             self.target_sequence_length: sequence_length})\n",
        "\n",
        "  def get_action_gradients(self, state, action, sequence_length):\n",
        "    ''' Returns ∇_a.Q(s, a|θ^µ). '''\n",
        "    return np.array(self.sess.run(self.action_gradients,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length})[0])\n",
        "\n",
        "  def init_target_network(self):\n",
        "    self.sess.run(self.init_target_network_params)\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.sess.run(self.update_target_network_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNP3jdofyh7M"
      },
      "source": [
        "# Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvIqtE2YzoUa"
      },
      "source": [
        "class ReplayMemory():\n",
        "  ''' Replay memory D in article. '''\n",
        "  \n",
        "  def __init__(self, buffer_size):\n",
        "    self.buffer_size = buffer_size\n",
        "    # self.buffer = [[row['state'], row['action'], row['reward'], row['n_state']] for _, row in data.iterrows()][-self.buffer_size:] TODO: empty or not?\n",
        "    self.buffer = []\n",
        "\n",
        "  def add(self, state, action, reward, n_state):\n",
        "    self.buffer.append([state, action, reward, n_state])\n",
        "    if len(self.buffer) > self.buffer_size:\n",
        "      self.buffer.pop(0)\n",
        "\n",
        "  def size(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def sample_batch(self, batch_size):\n",
        "    return random.sample(self.buffer, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x-ekweNfStD"
      },
      "source": [
        "def experience_replay(replay_memory, batch_size, actor, critic, embeddings, ra_length, state_space_size, action_space_size, discount_factor):\n",
        "  '''\n",
        "  Experience replay.\n",
        "  Args:\n",
        "    replay_memory: replay memory D in article.\n",
        "    batch_size: sample size.\n",
        "    actor: Actor network.\n",
        "    critic: Critic network.\n",
        "    embeddings: Embeddings object.\n",
        "    state_space_size: dimension of states.\n",
        "    action_space_size: dimensions of actions.\n",
        "  Returns:\n",
        "    Best Q-value, loss of Critic network for printing/recording purpose.\n",
        "  '''\n",
        "\n",
        "  # '22: Sample minibatch of N transitions (s, a, r, s′) from D'\n",
        "  samples = replay_memory.sample_batch(batch_size)\n",
        "  states = np.array([s[0] for s in samples])\n",
        "  actions = np.array([s[1] for s in samples])\n",
        "  rewards = np.array([s[2] for s in samples])\n",
        "  n_states = np.array([s[3] for s in samples]).reshape(-1, state_space_size)\n",
        "\n",
        "  # '23: Generate a′ by target Actor network according to Algorithm 2'\n",
        "  n_actions = actor.get_recommendation_list(ra_length, states, embeddings, target=True).reshape(-1, action_space_size)\n",
        "\n",
        "  # Calculate predicted Q′(s′, a′|θ^µ′) value\n",
        "  target_Q_value = critic.predict_target(n_states, n_actions, [ra_length] * batch_size)\n",
        "\n",
        "  # '24: Set y = r + γQ′(s′, a′|θ^µ′)'\n",
        "  expected_rewards = rewards + discount_factor * target_Q_value\n",
        "  \n",
        "  # '25: Update Critic by minimizing (y − Q(s, a|θ^µ))²'\n",
        "  critic_Q_value, critic_loss, _ = critic.train(states, actions, [ra_length] * batch_size, expected_rewards)\n",
        "  \n",
        "  # '26: Update the Actor using the sampled policy gradient'\n",
        "  action_gradients = critic.get_action_gradients(states, n_actions, [ra_length] * batch_size)\n",
        "  actor.train(states, [ra_length] * batch_size, action_gradients)\n",
        "\n",
        "  # '27: Update the Critic target networks'\n",
        "  critic.update_target_network()\n",
        "\n",
        "  # '28: Update the Actor target network'\n",
        "  actor.update_target_network()\n",
        "\n",
        "  return np.amax(critic_Q_value), critic_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzYw4cAhzYDF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRDXsrsMy69k"
      },
      "source": [
        "class OrnsteinUhlenbeckNoise:\n",
        "  ''' Noise for Actor predictions. '''\n",
        "  def __init__(self, action_space_size, mu=0, theta=0.5, sigma=0.2):\n",
        "    self.action_space_size = action_space_size\n",
        "    self.mu = mu\n",
        "    self.theta = theta\n",
        "    self.sigma = sigma\n",
        "    self.state = np.ones(self.action_space_size) * self.mu\n",
        "\n",
        "  def get(self):\n",
        "    self.state += self.theta * (self.mu - self.state) + self.sigma * np.random.rand(self.action_space_size)\n",
        "    return self.state\n",
        "\n",
        "def train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary):\n",
        "  ''' Algorithm 3 in article. '''\n",
        "\n",
        "  # Set up summary operators\n",
        "  def build_summaries():\n",
        "    episode_reward = tf.Variable(0.)\n",
        "    tf.summary.scalar('reward', episode_reward)\n",
        "    episode_max_Q = tf.Variable(0.)\n",
        "    tf.summary.scalar('max_Q_value', episode_max_Q)\n",
        "    critic_loss = tf.Variable(0.)\n",
        "    tf.summary.scalar('critic_loss', critic_loss)\n",
        "\n",
        "    summary_vars = [episode_reward, episode_max_Q, critic_loss]\n",
        "    summary_ops = tf.summary.merge_all()\n",
        "    return summary_ops, summary_vars\n",
        "\n",
        "  summary_ops, summary_vars = build_summaries()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  writer = tf.summary.FileWriter(filename_summary, sess.graph)\n",
        "\n",
        "  # '2: Initialize target network f′ and Q′'\n",
        "  actor.init_target_network()\n",
        "  critic.init_target_network()\n",
        "\n",
        "  # '3: Initialize the capacity of replay memory D'\n",
        "  replay_memory = ReplayMemory(buffer_size) # Memory D in article\n",
        "  replay = False\n",
        "\n",
        "\n",
        "  start_time = time.time()\n",
        "  for i_session in range(nb_episodes): # '4: for session = 1, M do'\n",
        "    session_reward = 0\n",
        "    session_Q_value = 0\n",
        "    session_critic_loss = 0\n",
        "\n",
        "    # '5: Reset the item space I' is useless because unchanged.\n",
        "\n",
        "    states = environment.reset() # '6: Initialize state s_0 from previous sessions'\n",
        "    \n",
        "    if (i_session + 1) % 10 == 0: # Update average parameters every 10 episodes\n",
        "      environment.groups = environment.get_groups()\n",
        "      \n",
        "    exploration_noise = OrnsteinUhlenbeckNoise(history_length * embeddings.size())\n",
        "\n",
        "    for t in range(nb_rounds): # '7: for t = 1, T do'\n",
        "      # '8: Stage 1: Transition Generating Stage'\n",
        "\n",
        "      # '9: Select an action a_t = {a_t^1, ..., a_t^K} according to Algorithm 2'\n",
        "      actions = actor.get_recommendation_list(\n",
        "          ra_length,\n",
        "          states.reshape(1, -1), # TODO + exploration_noise.get().reshape(1, -1),\n",
        "          embeddings).reshape(ra_length, embeddings.size())\n",
        "\n",
        "      # '10: Execute action a_t and observe the reward list {r_t^1, ..., r_t^K} for each item in a_t'\n",
        "      rewards, next_states = environment.step(actions)\n",
        "\n",
        "      # '19: Store transition (s_t, a_t, r_t, s_t+1) in D'\n",
        "      replay_memory.add(states.reshape(history_length * embeddings.size()),\n",
        "                        actions.reshape(ra_length * embeddings.size()),\n",
        "                        [rewards],\n",
        "                        next_states.reshape(history_length * embeddings.size()))\n",
        "\n",
        "      states = next_states # '20: Set s_t = s_t+1'\n",
        "\n",
        "      session_reward += rewards\n",
        "      \n",
        "      # '21: Stage 2: Parameter Updating Stage'\n",
        "      if replay_memory.size() >= batch_size: # Experience replay\n",
        "        replay = True\n",
        "        replay_Q_value, critic_loss = experience_replay(replay_memory, batch_size,\n",
        "          actor, critic, embeddings, ra_length, history_length * embeddings.size(),\n",
        "          ra_length * embeddings.size(), discount_factor)\n",
        "        session_Q_value += replay_Q_value\n",
        "        session_critic_loss += critic_loss\n",
        "\n",
        "      summary_str = sess.run(summary_ops,\n",
        "                             feed_dict={summary_vars[0]: session_reward,\n",
        "                                        summary_vars[1]: session_Q_value,\n",
        "                                        summary_vars[2]: session_critic_loss})\n",
        "      \n",
        "      writer.add_summary(summary_str, i_session)\n",
        "\n",
        "      '''\n",
        "      print(state_to_items(embeddings.embed(data['state'][0]), actor, ra_length, embeddings),\n",
        "            state_to_items(embeddings.embed(data['state'][0]), actor, ra_length, embeddings, True))\n",
        "      '''\n",
        "\n",
        "    str_loss = str('Loss=%0.4f' % session_critic_loss)\n",
        "    print(('Episode %d/%d Reward=%d Time=%ds ' + (str_loss if replay else 'No replay')) % (i_session + 1, nb_episodes, session_reward, time.time() - start_time))\n",
        "    start_time = time.time()\n",
        "\n",
        "  writer.close()\n",
        "  tf.train.Saver().save(sess, 'models.h5', write_meta_graph=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx_5zk2hll5e"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8vv6bRi5_ro"
      },
      "source": [
        "# Hyperparameters\n",
        "history_length = 12 # N in article\n",
        "ra_length = 4 # K in article\n",
        "discount_factor = 0.99 # Gamma in Bellman equation\n",
        "actor_lr = 0.0001\n",
        "critic_lr = 0.001\n",
        "tau = 0.001 # τ in Algorithm 3\n",
        "batch_size = 64\n",
        "nb_episodes = 100\n",
        "nb_rounds = 50\n",
        "filename_summary = 'summary.txt'\n",
        "alpha = 0.5 # α (alpha) in Equation (1)\n",
        "gamma = 0.9 # Γ (Gamma) in Equation (4)\n",
        "buffer_size = 1000000 # Size of replay memory D in article\n",
        "fixed_length = True # Fixed memory length\n",
        "\n",
        "dg = DataGenerator('ml-100k/u.data', 'ml-100k/u.item')\n",
        "dg.gen_train_test(0.8, seed=42)\n",
        "\n",
        "dg.write_csv('train.csv', dg.train, nb_states=[history_length], nb_actions=[ra_length])\n",
        "dg.write_csv('test.csv', dg.test, nb_states=[history_length], nb_actions=[ra_length])\n",
        "\n",
        "data = read_file('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-aa79rvlpWH"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezsuxZbllgDg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab05eafb-aa02-4fe2-ac3f-2629603b5e5f"
      },
      "source": [
        "if True: # Generate embeddings?\n",
        "  eg = EmbeddingsGenerator(dg.user_train, pd.read_csv('ml-100k/u.data', sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp']))\n",
        "  eg.train(nb_epochs=100)\n",
        "  train_loss, train_accuracy = eg.test(dg.user_train)\n",
        "  print('Train set: Loss=%.4f ; Accuracy=%.1f%%' % (train_loss, train_accuracy * 100))\n",
        "  test_loss, test_accuracy = eg.test(dg.user_test)\n",
        "  print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))\n",
        "  eg.save_embeddings('embeddings.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 493us/step - loss: 6.9269 - accuracy: 0.0092 - val_loss: 6.5422 - val_accuracy: 0.0128\n",
            "2/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 222us/step - loss: 6.4397 - accuracy: 0.0134 - val_loss: 6.3556 - val_accuracy: 0.0122\n",
            "3/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 6.2928 - accuracy: 0.0146 - val_loss: 6.2279 - val_accuracy: 0.0168\n",
            "4/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 6.2212 - accuracy: 0.0162 - val_loss: 6.1265 - val_accuracy: 0.0230\n",
            "5/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 6.1598 - accuracy: 0.0190 - val_loss: 6.0773 - val_accuracy: 0.0194\n",
            "6/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 6.0772 - accuracy: 0.0196 - val_loss: 6.0438 - val_accuracy: 0.0176\n",
            "7/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 6.1297 - accuracy: 0.0170 - val_loss: 6.0080 - val_accuracy: 0.0244\n",
            "8/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 6.0183 - accuracy: 0.0238 - val_loss: 5.9524 - val_accuracy: 0.0222\n",
            "9/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.9769 - accuracy: 0.0218 - val_loss: 5.9657 - val_accuracy: 0.0248\n",
            "10/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 211us/step - loss: 5.9678 - accuracy: 0.0262 - val_loss: 5.9413 - val_accuracy: 0.0252\n",
            "11/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 5.9376 - accuracy: 0.0242 - val_loss: 5.8763 - val_accuracy: 0.0300\n",
            "12/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 225us/step - loss: 5.9496 - accuracy: 0.0300 - val_loss: 5.8792 - val_accuracy: 0.0280\n",
            "13/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.9164 - accuracy: 0.0310 - val_loss: 5.8481 - val_accuracy: 0.0364\n",
            "14/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 226us/step - loss: 5.8720 - accuracy: 0.0276 - val_loss: 5.7841 - val_accuracy: 0.0398\n",
            "15/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 5.8265 - accuracy: 0.0352 - val_loss: 5.7734 - val_accuracy: 0.0456\n",
            "16/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 226us/step - loss: 5.8483 - accuracy: 0.0356 - val_loss: 5.7613 - val_accuracy: 0.0438\n",
            "17/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 224us/step - loss: 5.7893 - accuracy: 0.0376 - val_loss: 5.7934 - val_accuracy: 0.0440\n",
            "18/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 5.7488 - accuracy: 0.0424 - val_loss: 5.7398 - val_accuracy: 0.0502\n",
            "19/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 5.7833 - accuracy: 0.0430 - val_loss: 5.7043 - val_accuracy: 0.0542\n",
            "20/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.7207 - accuracy: 0.0468 - val_loss: 5.6583 - val_accuracy: 0.0590\n",
            "21/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 5.7477 - accuracy: 0.0460 - val_loss: 5.6772 - val_accuracy: 0.0528\n",
            "22/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 5.6781 - accuracy: 0.0550 - val_loss: 5.6133 - val_accuracy: 0.0712\n",
            "23/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 5.7073 - accuracy: 0.0550 - val_loss: 5.5882 - val_accuracy: 0.0638\n",
            "24/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.6747 - accuracy: 0.0622 - val_loss: 5.5172 - val_accuracy: 0.0728\n",
            "25/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 242us/step - loss: 5.5599 - accuracy: 0.0660 - val_loss: 5.5279 - val_accuracy: 0.0808\n",
            "26/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 240us/step - loss: 5.5723 - accuracy: 0.0650 - val_loss: 5.5213 - val_accuracy: 0.0748\n",
            "27/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 240us/step - loss: 5.5649 - accuracy: 0.0716 - val_loss: 5.4637 - val_accuracy: 0.0860\n",
            "28/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 238us/step - loss: 5.5218 - accuracy: 0.0734 - val_loss: 5.4714 - val_accuracy: 0.0924\n",
            "29/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 5.4861 - accuracy: 0.0756 - val_loss: 5.4448 - val_accuracy: 0.0816\n",
            "30/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 5.4544 - accuracy: 0.0812 - val_loss: 5.3718 - val_accuracy: 0.0932\n",
            "31/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 5.4565 - accuracy: 0.0824 - val_loss: 5.3208 - val_accuracy: 0.1058\n",
            "32/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 5.4889 - accuracy: 0.0828 - val_loss: 5.3315 - val_accuracy: 0.1032\n",
            "33/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 5.4052 - accuracy: 0.0958 - val_loss: 5.3067 - val_accuracy: 0.1118\n",
            "34/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.4154 - accuracy: 0.0972 - val_loss: 5.2533 - val_accuracy: 0.1074\n",
            "35/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.3415 - accuracy: 0.0918 - val_loss: 5.1914 - val_accuracy: 0.1238\n",
            "36/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 5.2722 - accuracy: 0.1032 - val_loss: 5.1910 - val_accuracy: 0.1226\n",
            "37/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.3042 - accuracy: 0.1048 - val_loss: 5.1172 - val_accuracy: 0.1422\n",
            "38/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 5.2738 - accuracy: 0.1062 - val_loss: 5.1475 - val_accuracy: 0.1340\n",
            "39/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 5.1924 - accuracy: 0.1192 - val_loss: 5.0495 - val_accuracy: 0.1434\n",
            "40/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 5.1954 - accuracy: 0.1158 - val_loss: 5.0812 - val_accuracy: 0.1488\n",
            "41/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 5.1684 - accuracy: 0.1226 - val_loss: 5.0131 - val_accuracy: 0.1532\n",
            "42/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 5.0966 - accuracy: 0.1314 - val_loss: 4.9307 - val_accuracy: 0.1580\n",
            "43/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 5.0699 - accuracy: 0.1356 - val_loss: 4.9386 - val_accuracy: 0.1546\n",
            "44/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 225us/step - loss: 5.0264 - accuracy: 0.1414 - val_loss: 4.8890 - val_accuracy: 0.1654\n",
            "45/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 225us/step - loss: 5.0789 - accuracy: 0.1376 - val_loss: 4.9144 - val_accuracy: 0.1800\n",
            "46/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 5.0062 - accuracy: 0.1472 - val_loss: 4.8201 - val_accuracy: 0.1830\n",
            "47/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 4.9469 - accuracy: 0.1472 - val_loss: 4.7793 - val_accuracy: 0.1942\n",
            "48/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 4.9043 - accuracy: 0.1576 - val_loss: 4.7465 - val_accuracy: 0.1954\n",
            "49/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 212us/step - loss: 4.8448 - accuracy: 0.1704 - val_loss: 4.7257 - val_accuracy: 0.1998\n",
            "50/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 4.8976 - accuracy: 0.1642 - val_loss: 4.6886 - val_accuracy: 0.2168\n",
            "51/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 226us/step - loss: 4.8724 - accuracy: 0.1688 - val_loss: 4.6863 - val_accuracy: 0.2090\n",
            "52/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 229us/step - loss: 4.7865 - accuracy: 0.1714 - val_loss: 4.6158 - val_accuracy: 0.2128\n",
            "53/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 4.7217 - accuracy: 0.1862 - val_loss: 4.5954 - val_accuracy: 0.2274\n",
            "54/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 4.6736 - accuracy: 0.1818 - val_loss: 4.6328 - val_accuracy: 0.2236\n",
            "55/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 4.6548 - accuracy: 0.1976 - val_loss: 4.5309 - val_accuracy: 0.2444\n",
            "56/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 4.6338 - accuracy: 0.1920 - val_loss: 4.4021 - val_accuracy: 0.2620\n",
            "57/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 224us/step - loss: 4.6152 - accuracy: 0.2106 - val_loss: 4.3897 - val_accuracy: 0.2662\n",
            "58/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 211us/step - loss: 4.5694 - accuracy: 0.2084 - val_loss: 4.3861 - val_accuracy: 0.2658\n",
            "59/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 4.5311 - accuracy: 0.2268 - val_loss: 4.3321 - val_accuracy: 0.2712\n",
            "60/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 4.4327 - accuracy: 0.2392 - val_loss: 4.2879 - val_accuracy: 0.2872\n",
            "61/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 213us/step - loss: 4.4544 - accuracy: 0.2346 - val_loss: 4.2366 - val_accuracy: 0.2974\n",
            "62/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 224us/step - loss: 4.3917 - accuracy: 0.2448 - val_loss: 4.1548 - val_accuracy: 0.3138\n",
            "63/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 224us/step - loss: 4.4183 - accuracy: 0.2354 - val_loss: 4.1214 - val_accuracy: 0.3130\n",
            "64/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 4.3409 - accuracy: 0.2490 - val_loss: 4.1615 - val_accuracy: 0.3204\n",
            "65/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 4.2842 - accuracy: 0.2622 - val_loss: 4.0126 - val_accuracy: 0.3374\n",
            "66/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 4.2558 - accuracy: 0.2644 - val_loss: 4.0099 - val_accuracy: 0.3456\n",
            "67/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 4.2744 - accuracy: 0.2638 - val_loss: 3.9976 - val_accuracy: 0.3374\n",
            "68/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 234us/step - loss: 4.1018 - accuracy: 0.2864 - val_loss: 3.8665 - val_accuracy: 0.3662\n",
            "69/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 4.1013 - accuracy: 0.2910 - val_loss: 3.8658 - val_accuracy: 0.3618\n",
            "70/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 4.0316 - accuracy: 0.3050 - val_loss: 3.8712 - val_accuracy: 0.3672\n",
            "71/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 222us/step - loss: 3.9658 - accuracy: 0.3144 - val_loss: 3.7949 - val_accuracy: 0.3838\n",
            "72/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 224us/step - loss: 3.9538 - accuracy: 0.3202 - val_loss: 3.7268 - val_accuracy: 0.3952\n",
            "73/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 213us/step - loss: 3.8889 - accuracy: 0.3232 - val_loss: 3.6783 - val_accuracy: 0.4126\n",
            "74/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 3.8493 - accuracy: 0.3348 - val_loss: 3.6740 - val_accuracy: 0.3916\n",
            "75/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 3.8447 - accuracy: 0.3384 - val_loss: 3.6290 - val_accuracy: 0.4184\n",
            "76/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 3.7314 - accuracy: 0.3544 - val_loss: 3.5281 - val_accuracy: 0.4338\n",
            "77/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 3.7217 - accuracy: 0.3532 - val_loss: 3.5206 - val_accuracy: 0.4370\n",
            "78/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 3.6536 - accuracy: 0.3702 - val_loss: 3.4371 - val_accuracy: 0.4494\n",
            "79/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 3.6961 - accuracy: 0.3648 - val_loss: 3.4285 - val_accuracy: 0.4496\n",
            "80/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 3.6129 - accuracy: 0.3772 - val_loss: 3.3229 - val_accuracy: 0.4754\n",
            "81/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 3.5680 - accuracy: 0.3864 - val_loss: 3.3086 - val_accuracy: 0.4836\n",
            "82/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 213us/step - loss: 3.4320 - accuracy: 0.4010 - val_loss: 3.2259 - val_accuracy: 0.5046\n",
            "83/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 3.4232 - accuracy: 0.4124 - val_loss: 3.1715 - val_accuracy: 0.5058\n",
            "84/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 213us/step - loss: 3.4413 - accuracy: 0.4088 - val_loss: 3.1572 - val_accuracy: 0.5140\n",
            "85/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 225us/step - loss: 3.3428 - accuracy: 0.4220 - val_loss: 3.1092 - val_accuracy: 0.5228\n",
            "86/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 213us/step - loss: 3.2983 - accuracy: 0.4358 - val_loss: 3.1422 - val_accuracy: 0.5188\n",
            "87/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 3.2342 - accuracy: 0.4500 - val_loss: 3.0764 - val_accuracy: 0.5332\n",
            "88/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 209us/step - loss: 3.2516 - accuracy: 0.4524 - val_loss: 2.9602 - val_accuracy: 0.5420\n",
            "89/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 3.1939 - accuracy: 0.4610 - val_loss: 2.9346 - val_accuracy: 0.5484\n",
            "90/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 225us/step - loss: 3.1554 - accuracy: 0.4710 - val_loss: 2.9109 - val_accuracy: 0.5556\n",
            "91/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 224us/step - loss: 3.1203 - accuracy: 0.4726 - val_loss: 2.8296 - val_accuracy: 0.5684\n",
            "92/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 223us/step - loss: 3.0487 - accuracy: 0.4844 - val_loss: 2.7578 - val_accuracy: 0.5854\n",
            "93/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 3.0641 - accuracy: 0.4784 - val_loss: 2.7113 - val_accuracy: 0.5876\n",
            "94/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 2.9476 - accuracy: 0.5062 - val_loss: 2.7528 - val_accuracy: 0.5980\n",
            "95/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 2.8935 - accuracy: 0.5138 - val_loss: 2.6579 - val_accuracy: 0.5992\n",
            "96/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 213us/step - loss: 2.8231 - accuracy: 0.5216 - val_loss: 2.6450 - val_accuracy: 0.6082\n",
            "97/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 2.8205 - accuracy: 0.5254 - val_loss: 2.5472 - val_accuracy: 0.6288\n",
            "98/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 237us/step - loss: 2.8335 - accuracy: 0.5204 - val_loss: 2.5537 - val_accuracy: 0.6252\n",
            "99/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 239us/step - loss: 2.7278 - accuracy: 0.5466 - val_loss: 2.5060 - val_accuracy: 0.6352\n",
            "100/100\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 2.7283 - accuracy: 0.5432 - val_loss: 2.4455 - val_accuracy: 0.6436\n",
            "100000/100000 [==============================] - 6s 64us/step\n",
            "Train set: Loss=2.4179 ; Accuracy=64.9%\n",
            "100000/100000 [==============================] - 6s 63us/step\n",
            "Test set: Loss=12.0068 ; Accuracy=3.3%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1e498fa8-fb1f-4ea8-82b4-08f113ae832a\", \"embeddings.csv\", 1906270)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UI61hVlyQLS"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wurA3IXNliMy"
      },
      "source": [
        "embeddings = Embeddings(read_embeddings('embeddings.csv'))\n",
        "\n",
        "state_space_size = embeddings.size() * history_length\n",
        "action_space_size = embeddings.size() * ra_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP4vzcHwOmbP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "c19579df-4f47-4882-c017-291e71bcfac1"
      },
      "source": [
        "environment = Environment(data, embeddings, alpha, gamma, fixed_length)\n",
        "\n",
        "tf.reset_default_graph() # For multiple consecutive executions\n",
        "\n",
        "sess = tf.Session()\n",
        "# '1: Initialize actor network f_θ^π and critic network Q(s, a|θ^µ) with random weights'\n",
        "actor = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
        "critic = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
        "\n",
        "train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-1a5cd2de5f02>:69: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-13-1a5cd2de5f02>:70: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-13-1a5cd2de5f02>:40: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Episode 1/100 Reward=545 Time=5s No replay\n",
            "Episode 2/100 Reward=545 Time=58s Loss=1099.0093\n",
            "Episode 3/100 Reward=545 Time=75s Loss=50.0000\n",
            "Episode 4/100 Reward=545 Time=76s Loss=33.1675\n",
            "Episode 5/100 Reward=545 Time=75s Loss=24.5507\n",
            "Episode 6/100 Reward=545 Time=76s Loss=16.8803\n",
            "Episode 7/100 Reward=545 Time=75s Loss=13.8466\n",
            "Episode 8/100 Reward=545 Time=75s Loss=11.3427\n",
            "Episode 9/100 Reward=545 Time=76s Loss=10.5354\n",
            "Episode 10/100 Reward=545 Time=76s Loss=8.5880\n",
            "Episode 11/100 Reward=545 Time=75s Loss=7.4289\n",
            "Episode 12/100 Reward=545 Time=75s Loss=6.3215\n",
            "Episode 13/100 Reward=545 Time=74s Loss=5.5869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2b61e1f64844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcritic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_space_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-1e63ee7cf8b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)\u001b[0m\n\u001b[1;32m     83\u001b[0m         replay_Q_value, critic_loss = experience_replay(replay_memory, batch_size,\n\u001b[1;32m     84\u001b[0m           \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m           ra_length * embeddings.size(), discount_factor)\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0msession_Q_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreplay_Q_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0msession_critic_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-89b559ba4c36>\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(replay_memory, batch_size, actor, critic, embeddings, ra_length, state_space_size, action_space_size, discount_factor)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# '23: Generate a′ by target Actor network according to Algorithm 2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recommendation_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# Calculate predicted Q′(s′, a′|θ^µ′) value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1a5cd2de5f02>\u001b[0m in \u001b[0;36mget_recommendation_list\u001b[0;34m(self, ra_length, noisy_state, embeddings, target)\u001b[0m\n\u001b[1;32m    135\u001b[0m       for embedding in embeddings.get_embedding_vector()]\n\u001b[1;32m    136\u001b[0m       for k in range(ra_length)]\n\u001b[0;32m--> 137\u001b[0;31m       for i in range(batch_size)])\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# '8: return a_t'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1a5cd2de5f02>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m       for embedding in embeddings.get_embedding_vector()]\n\u001b[1;32m    136\u001b[0m       for k in range(ra_length)]\n\u001b[0;32m--> 137\u001b[0;31m       for i in range(batch_size)])\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# '8: return a_t'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1a5cd2de5f02>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m     scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n\u001b[1;32m    135\u001b[0m       for embedding in embeddings.get_embedding_vector()]\n\u001b[0;32m--> 136\u001b[0;31m       for k in range(ra_length)]\n\u001b[0m\u001b[1;32m    137\u001b[0m       for i in range(batch_size)])\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1a5cd2de5f02>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# '3: Score items in I according to Equation (6)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n\u001b[0;32m--> 135\u001b[0;31m       for embedding in embeddings.get_embedding_vector()]\n\u001b[0m\u001b[1;32m    136\u001b[0m       for k in range(ra_length)]\n\u001b[1;32m    137\u001b[0m       for i in range(batch_size)])\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOnK_UxHzaPa"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsJ0klBBSSXn"
      },
      "source": [
        "dict_embeddings = {}\n",
        "for i, item in enumerate(embeddings.get_embedding_vector()):\n",
        "  str_item = str(item)\n",
        "  assert(str_item not in dict_embeddings)\n",
        "  dict_embeddings[str_item] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-LsmlHnyouJ"
      },
      "source": [
        "def state_to_items(state, actor, ra_length, embeddings, dict_embeddings, target=False):\n",
        "  return [dict_embeddings[str(action)]\n",
        "          for action in actor.get_recommendation_list(ra_length, np.array(state).reshape(1, -1), embeddings, target).reshape(ra_length, embeddings.size())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnCn8bf58uAP"
      },
      "source": [
        "def test_actor(actor, test_df, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1):\n",
        "  ratings = []\n",
        "  unknown = 0\n",
        "  random_seen = []\n",
        "  for _ in range(nb_rounds):\n",
        "    for i in range(len(test_df)):\n",
        "      history_sample = list(test_df[i].sample(history_length)['itemId'])\n",
        "      recommendation = state_to_items(embeddings.embed(history_sample), actor, ra_length, embeddings, dict_embeddings, target)\n",
        "      for item in recommendation:\n",
        "        l = list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])\n",
        "        assert(len(l) < 2)\n",
        "        if len(l) == 0:\n",
        "          unknown += 1\n",
        "        else:\n",
        "          ratings.append(l[0])\n",
        "      for item in history_sample:\n",
        "        random_seen.append(list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])[0])\n",
        "\n",
        "  return ratings, unknown, random_seen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0j3nHjUAP24"
      },
      "source": [
        "## Train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBZr_opifZss"
      },
      "source": [
        "#### Target = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgqFYAsd8W-S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fb4f8f4-69f7-419c-f5b5-b9d3c4938212"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.train, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=10)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.0% unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGetmkeD95rP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "55ffa85b-f981-4ce0-b2ca-33d6bcd22c12"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ34zs4Jx4jczK5j/DxNZQVsV/0fdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FPKh8gafdcn"
      },
      "source": [
        "#### Target = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvjYl_LTfGi9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef427de1-7ef5-45cd-d02f-8f00979f54d3"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.train, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=10)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.9% unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IKYVQ6gfIXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f2fd236e-593e-4e74-a443-27098dc07122"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH3ac9ZUsdL12AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFimdOkLASAn"
      },
      "source": [
        "## Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x49sZSZIfgfN"
      },
      "source": [
        "#### Target = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXhBwo6t-p5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9fe413f-a1c0-4f1a-b075-6e167ffa3b0a"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=100)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.4% unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFPjENrZAVsc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c819ff25-5791-46b0-f496-ba39f2577c36"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB/VT2V3T7W2QAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg4QPFo7fkzn"
      },
      "source": [
        "#### Target = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HCCXmcsAYkK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63f646b3-f000-4851-ecea-96e86cf55fb2"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=100)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.5% unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5T4zKcJfTa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "fd0c6487-016f-49e7-c211-21194e887262"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEICAYAAABVv+9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVKRoOm7k_fn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}