{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:36:51.613802Z",
     "start_time": "2020-12-14T14:36:46.650341Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "                    \n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchtools.optim import Ranger\n",
    "# from ranger import Ranger\n",
    "from adabelief_pytorch import AdaBelief\n",
    "\n",
    "import adabelief_pytorch\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n",
    "- data: Books.csv\n",
    "- 'item', 'user' 동일 데이터 중복 제거\n",
    "- item_counts >= 10\n",
    "- user_counts >= 20\n",
    "- 총 13315087\n",
    "- user unique: 256198\n",
    "- item unique: 636312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:36:53.918753Z",
     "start_time": "2020-12-14T14:36:51.614825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>3094405</td>\n",
       "      <td>5</td>\n",
       "      <td>1112140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>14877871</td>\n",
       "      <td>5</td>\n",
       "      <td>1466380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>7151803</td>\n",
       "      <td>5</td>\n",
       "      <td>1436400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>10069097</td>\n",
       "      <td>5</td>\n",
       "      <td>1383436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>13327705</td>\n",
       "      <td>5</td>\n",
       "      <td>1357084800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item      user  rating   timestamp\n",
       "0   122   3094405       5  1112140800\n",
       "1   122  14877871       5  1466380800\n",
       "2   122   7151803       5  1436400000\n",
       "3   122  10069097       5  1383436800\n",
       "4   122  13327705       5  1357084800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = './data/data_final.csv'\n",
    "columns =  ['item', 'user', 'rating', 'timestamp']\n",
    "df = pd.read_csv(datapath, sep = \",\", names = columns, dtype = int)\n",
    "df.astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:30.615891Z",
     "start_time": "2020-12-14T14:36:53.920155Z"
    }
   },
   "outputs": [],
   "source": [
    "users_df = df.sort_values([\"user\",\"timestamp\"]).set_index(\"user\").fillna(0).drop(\"timestamp\",axis=1)\n",
    "users = dict(tuple(df.groupby(\"user\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:30.619138Z",
     "start_time": "2020-12-14T14:37:30.616814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13315087, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:30.796802Z",
     "start_time": "2020-12-14T14:37:30.619909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256198"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:30.869428Z",
     "start_time": "2020-12-14T14:37:30.797560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['item'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:31.306476Z",
     "start_time": "2020-12-14T14:37:30.870327Z"
    }
   },
   "outputs": [],
   "source": [
    "# 고유한 유저, 아티스트를 찾아내는 코드\n",
    "user_unique = df['user'].unique()\n",
    "item_unique = df['item'].unique()\n",
    "\n",
    "# 유저, 아티스트 indexing 하는 코드 idx는 index의 약자입니다.\n",
    "user_to_idx = {v:k for k,v in enumerate(user_unique)}\n",
    "idx_to_user = {k:v for k,v in enumerate(user_unique)}\n",
    "item_to_idx = {v:k for k,v in enumerate(item_unique)}\n",
    "idx_to_item = {k:v for k,v in enumerate(item_unique)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:41.485364Z",
     "start_time": "2020-12-14T14:37:31.308201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId column indexing OK!!\n",
      "itemId column indexing OK!!\n"
     ]
    }
   ],
   "source": [
    "# indexing을 통해 데이터 컬럼 내 값을 바꾸는 코드\n",
    "# dictionary 자료형의 get 함수는 https://wikidocs.net/16 을 참고하세요.\n",
    "\n",
    "# user_to_idx.get을 통해 user_id 컬럼의 모든 값을 인덱싱한 Series를 구해 봅시다. \n",
    "# 혹시 정상적으로 인덱싱되지 않은 row가 있다면 인덱스가 NaN이 될 테니 dropna()로 제거합니다. \n",
    "temp_user_data = df['user'].map(user_to_idx.get).dropna()\n",
    "if len(temp_user_data) == len(df):   # 모든 row가 정상적으로 인덱싱되었다면\n",
    "    print('userId column indexing OK!!')\n",
    "    df['user'] = temp_user_data   # data['userId']을 인덱싱된 Series로 교체해 줍니다. \n",
    "else:\n",
    "    print('userId column indexing Fail!!')\n",
    "\n",
    "# movie_to_idx을 통해 artist 컬럼도 동일한 방식으로 인덱싱해 줍니다. \n",
    "temp_item_data = df['item'].map(item_to_idx.get).dropna()\n",
    "if len(temp_item_data) == len(df):\n",
    "    print('itemId column indexing OK!!')\n",
    "    df['item'] = temp_item_data\n",
    "else:\n",
    "    print('itemId column indexing Fail!!')\n",
    "# up_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csr_matrix 및 embedding(ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:37:42.079751Z",
     "start_time": "2020-12-14T14:37:41.486683Z"
    }
   },
   "outputs": [],
   "source": [
    "num_user = df['user'].nunique()\n",
    "num_item = df['item'].nunique()\n",
    "\n",
    "csr_data = csr_matrix((df['rating'], (df.user, df.item)), shape= (num_user, num_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:15.567059Z",
     "start_time": "2020-12-14T14:37:42.080831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d834f65f513d4b9d80a24ace7c419b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#num_threads=-1\n",
    "als_model = AlternatingLeastSquares(factors=100, regularization=0.01,use_gpu=False,\n",
    "                                    iterations=15,dtype=np.float32,calculate_training_loss=True, num_threads=1)\n",
    "\n",
    "#item x user\n",
    "csr_data_transpose = csr_data.T\n",
    "# csr_data_transpose\n",
    "als_model.fit(csr_data_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:21.952525Z",
     "start_time": "2020-12-14T14:40:15.568296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636312/636312 [00:04<00:00, 148835.93it/s]\n",
      "100%|██████████| 256198/256198 [00:02<00:00, 121861.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256198"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings_dict = {idx_to_item[i]:tf.convert_to_tensor(als_model.item_factors[i]) for i in tqdm.tqdm(range(num_item))}\n",
    "user_embeddings_dict = {idx_to_user[i]:tf.convert_to_tensor(als_model.user_factors[i]) for i in tqdm.tqdm(range(num_user))}\n",
    "\n",
    "len(user_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:21.955684Z",
     "start_time": "2020-12-14T14:40:21.953426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:21.966604Z",
     "start_time": "2020-12-14T14:40:21.956558Z"
    }
   },
   "outputs": [],
   "source": [
    "# item_embeddings_dict = np.load(\"./item_embeddings_dict_final_1.npy\", allow_pickle=True).item()\n",
    "# user_embeddings_dict = np.load(\"./user_embeddings_dict_final_1.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:21.976582Z",
     "start_time": "2020-12-14T14:40:21.967454Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save(\"item_embeddings_dict_final_1.npy\", item_embeddings_dict)\n",
    "# np.save(\"user_embeddings_dict_final_1.npy\", user_embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train and Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive rating(4, 5)이 10개 이상인 user만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.090402Z",
     "start_time": "2020-12-14T14:40:21.977437Z"
    }
   },
   "outputs": [],
   "source": [
    "#Getting users with positive rating count greater than 10 \n",
    "# 10 == 'N' positively interacted items\n",
    "# from collections import defaultdict\n",
    "# from collections import Counter\n",
    "users_dict = defaultdict(dict)\n",
    "users_id_list = set()\n",
    "for user_id in users:\n",
    "    rating_freq = Counter(users[user_id][\"rating\"].values)\n",
    "    if rating_freq[4]+rating_freq[5]<10 :\n",
    "        continue    \n",
    "    else:\n",
    "        users_id_list.add(int(user_id))\n",
    "        users_dict[user_id][\"item\"] = users[user_id][\"item\"].values\n",
    "        users_dict[user_id][\"rating\"] = users[user_id][\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.094099Z",
     "start_time": "2020-12-14T14:40:41.091351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 2, 2, 2, 4, 4, 3, 4, 3, 5, 5, 3, 4, 5, 4, 5, 5, 4, 2, 1, 2,\n",
       "       2, 2, 4, 5, 4, 1, 2, 4, 4, 3, 5, 4, 4, 5, 5, 1, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dict[14680070][\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.129182Z",
     "start_time": "2020-12-14T14:40:41.094920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12058627 14680070  7340040 ...  9437172 12058615 11010043]\n"
     ]
    }
   ],
   "source": [
    "users_id_list = np.array(list(users_id_list))\n",
    "print(users_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.140371Z",
     "start_time": "2020-12-14T14:40:41.130014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': array([  28067,   41744,   81990,   94755,   95277,  104841,  122183,\n",
      "        177661,  180581,  183115,  211122,  233553,  271914,  284884,\n",
      "        286968,  300146,  339862,  343635,  364176,  364388,  364375,\n",
      "        411644,  445202,  463239,  512989,  632956,  723559,  755129,\n",
      "        809664,  819077,  819739,  878301,  951090, 1009123, 1010557,\n",
      "       1042421, 1071233, 1107949, 1112160, 1125199, 1341839, 1347405,\n",
      "       1487939, 1514645, 1580541, 1928572, 1956531, 1956306, 1962144,\n",
      "       1972774, 1983891, 2009311, 2015798, 2031750, 2098284, 2127133,\n",
      "       2233093, 2285383, 2295964, 2295969, 2295970, 2301303, 2305905,\n",
      "       2388411, 2390438, 2542197,  527007, 2791251,  180670,  199910,\n",
      "        271858,  293239,  441781,  538337,  544191,  766746,  955067,\n",
      "        962416, 1010621, 1025036, 1151374, 1181909, 1889954, 2108769]), 'rating': array([4, 5, 4, 4, 5, 5, 3, 4, 5, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 4, 1, 5,\n",
      "       5, 5, 4, 5, 5, 5, 1, 4, 5, 5, 5, 4, 5, 4, 5, 2, 5, 5, 4, 5, 5, 4,\n",
      "       5, 5, 4, 5, 3, 5, 5, 5, 4, 5, 5, 1, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5,\n",
      "       4, 4, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 4, 1, 5, 5])}\n"
     ]
    }
   ],
   "source": [
    "print(users_dict[12058627])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.151298Z",
     "start_time": "2020-12-14T14:40:41.141553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252110"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.167257Z",
     "start_time": "2020-12-14T14:40:41.152143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14193484 10110561]\n"
     ]
    }
   ],
   "source": [
    "#choosing default train_test_split of 25%\n",
    "train_users,test_users = train_test_split(users_id_list)\n",
    "print(train_users[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.172269Z",
     "start_time": "2020-12-14T14:40:41.168380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7588454  497764]\n"
     ]
    }
   ],
   "source": [
    "print(test_users[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive rating(4, 5)을 10개까지 모아서 UserDataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.183061Z",
     "start_time": "2020-12-14T14:40:41.173501Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self,users_list,users_dict):\n",
    "        self.users_list = users_list\n",
    "        self.users_dict = users_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users_list)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        user_id = self.users_list[idx]\n",
    "        items = [('1',)]*10\n",
    "        ratings = [('0',)]*10\n",
    "        j=0\n",
    "        for i,rate in enumerate(self.users_dict[user_id][\"rating\"]):\n",
    "            if int(rate) >3 and j < 10:\n",
    "                items[j] = self.users_dict[user_id][\"item\"][i]\n",
    "                ratings[j] = self.users_dict[user_id][\"rating\"][i]\n",
    "                j += 1\n",
    "        # item = list(self.users_dict[user_id][\"item\"][:])\n",
    "        # rating = list(self.users_dict[user_id][\"rating\"][:])\n",
    "        size = len(items)\n",
    "    \n",
    "        return {'item':items,'rating':ratings,'size':size,'userid':user_id,'idx':idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.193425Z",
     "start_time": "2020-12-14T14:40:41.185946Z"
    }
   },
   "outputs": [],
   "source": [
    "train_users_dataset = UserDataset(train_users,users_dict)\n",
    "test_users_dataset = UserDataset(test_users,users_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.207313Z",
     "start_time": "2020-12-14T14:40:41.194860Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_users_dataset, batch_size=1)\n",
    "test_dataloader = DataLoader(test_users_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.218050Z",
     "start_time": "2020-12-14T14:40:41.208652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189082\n"
     ]
    }
   ],
   "source": [
    "train_num = len(train_dataloader)\n",
    "print(train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.232071Z",
     "start_time": "2020-12-14T14:40:41.218886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63028\n"
     ]
    }
   ],
   "source": [
    "test_num = len(test_dataloader)\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. State Representation Models¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR-ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:43:56.164320Z",
     "start_time": "2020-12-14T14:43:56.159638Z"
    }
   },
   "outputs": [],
   "source": [
    "''' input\n",
    "    # dataloader에서 나온 return들\n",
    "    # user_idb : 해당 user의 id \n",
    "    # itemb : 유저가 rating 한 item id 10개(tensor))\n",
    "    # memory :  유저가 rating 한 item들 list 크기는 유저 * 10(item)  \n",
    "    idx : user_list에서 user의 index\n",
    "    output\n",
    "    state : #state tensor shape [3,100]\n",
    "'''\n",
    "def drrave_state_rep(userid_b, memory, idx):\n",
    "    user_num = idx\n",
    "    H = [] #item embeddings\n",
    "    user_n_items = memory\n",
    "    user_embeddings = torch.Tensor(np.array(user_embeddings_dict[int(userid_b[0])]),).unsqueeze(0)\n",
    "\n",
    "    for item in user_n_items:\n",
    "        H.append(np.array(item_embeddings_dict[int(item)]))\n",
    "    # avg_layer = nn.AvgPool1d(1)  # pooling layer 사용 \n",
    "    weighted_avg_layer = nn.Conv1d(in_channels= 10, out_channels=1, kernel_size=1)\n",
    "    item_embeddings = weighted_avg_layer(torch.Tensor(H,).unsqueeze(0)).permute(0,2,1).squeeze(0)\n",
    "    \n",
    "    state = torch.cat([user_embeddings,user_embeddings*item_embeddings.T,item_embeddings.T])\n",
    "\n",
    "    return state #state tensor shape [3,100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRR-u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.253019Z",
     "start_time": "2020-12-14T14:40:41.243899Z"
    }
   },
   "outputs": [],
   "source": [
    "# def drru_state_rep(userid_b,items,memory,idx):\n",
    "#     user_num = idx\n",
    "#     H = []\n",
    "#     user_n_items = items\n",
    "#     user_embeddings = user_embeddings_dict[userid_b[0]]\n",
    "#     for i,item in enumerate(user_n_items):\n",
    "#         ui = np.array(user_embeddings) * np.array(movie_embeddings_dict[item[0]])\n",
    "#         H.append(ui)\n",
    "\n",
    "#     pairs = list(itertools.combinations(memory[user_num], 2))\n",
    "#     for item1,item2 in pairs:\n",
    "#         pair1 =  np.array(movie_embeddings_dict[str(int(item1))])\n",
    "#         pair2 = np.array(movie_embeddings_dict[str(int(item2))])\n",
    "\n",
    "#         product = pair1*pair2\n",
    "#         H.append(product)\n",
    "#     state = torch.Tensor(H,)\n",
    "#     return state #state tensor shape [55,100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRR-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.269120Z",
     "start_time": "2020-12-14T14:40:41.253950Z"
    }
   },
   "outputs": [],
   "source": [
    "# def drrp_state_rep(items,memory,idx):\n",
    "#   user_num = idx\n",
    "#   H = []\n",
    "#   user_n_items = items\n",
    "#   for i,item in enumerate(user_n_items):\n",
    "#     H.append(np.array(movie_embeddings_dict[item[0]]))\n",
    "  \n",
    "#   pairs = list(itertools.combinations(memory[user_num], 2))\n",
    "#   for item1,item2 in pairs:\n",
    "#     pair1 =  np.array(movie_embeddings_dict[str(int(item1))])\n",
    "#     pair2 = np.array(movie_embeddings_dict[str(int(item2))])\n",
    "#     product = pair1*pair2\n",
    "#     H.append(product)\n",
    "#   state = torch.Tensor(H,)\n",
    "#   return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state-rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.280493Z",
     "start_time": "2020-12-14T14:40:41.269907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef state_rep(item_b):\\n    state = []\\n    user_embeddings = np.zeros((len(columns),100))\\n    item_ids = list(item[0] for item in item_b)\\n    for i,subitem in enumerate(user_embeddings):\\n        if idx_to_id[i] in item_ids:\\n            user_embeddings[i] = np.array(item_embeddings_dict[idx_to_id[i]])\\n        else:\\n            user_embeddings[i] = np.zeros((100,))\\n    state = torch.Tensor(user_embeddings,)\\n    return torch.reshape(state,[-1]) \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just n items and their embeddings used to represent state\n",
    "'''\n",
    "def state_rep(item_b):\n",
    "    state = []\n",
    "    user_embeddings = np.zeros((len(columns),100))\n",
    "    item_ids = list(item[0] for item in item_b)\n",
    "    for i,subitem in enumerate(user_embeddings):\n",
    "        if idx_to_id[i] in item_ids:\n",
    "            user_embeddings[i] = np.array(item_embeddings_dict[idx_to_id[i]])\n",
    "        else:\n",
    "            user_embeddings[i] = np.zeros((100,))\n",
    "    state = torch.Tensor(user_embeddings,)\n",
    "    return torch.reshape(state,[-1]) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Actor, Critic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:40:41.290191Z",
     "start_time": "2020-12-14T14:40:41.281639Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/pabloppp/pytorch-tools@0.2.4 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:38.713491Z",
     "start_time": "2020-12-14T14:52:38.709055Z"
    }
   },
   "outputs": [],
   "source": [
    "#Actor Model:\n",
    "#Generating an action a based on state s\n",
    "\n",
    "# Input_dim 5500, output_dim 100, hidden_dim 256 for drr-u, p\n",
    "# Input_dim 2100, output_dim 100, hidden_dim 256 for drr-ave\n",
    "\n",
    "# embedding을 normalize(-1, 1) => tanh\n",
    "# embedding을 standard scaling => PCA whitening\n",
    "\n",
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,hidden_dim):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.drop_layer = nn.Dropout(p=0.5)        \n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state.to(device)))\n",
    "        # print(x.shape)\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        # print(x.shape)\n",
    "        x = self.drop_layer(x)\n",
    "        # x = torch.tanh(self.linear3(x)) # in case embeds are -1 1 normalized\n",
    "        x = self.linear3(x) # in case embeds are standard scaled / wiped using PCA whitening\n",
    "        # return state, x\n",
    "        return x # state = self.state_rep(state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:39.480982Z",
     "start_time": "2020-12-14T14:52:39.476702Z"
    }
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim,hidden_dim):\n",
    "\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(p=0.5)\n",
    "    \n",
    "        self.linear1 = nn.Linear(input_dim + output_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self,state,action):    \n",
    "        x = torch.cat([state.to(device), action.to(device)], 1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PER buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:27:35.002868Z",
     "start_time": "2020-12-14T14:27:34.985894Z"
    }
   },
   "source": [
    "SegmentTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:41.378250Z",
     "start_time": "2020-12-14T14:52:41.366204Z"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "class SegmentTree(object):\n",
    "    def __init__(self, capacity, operation, neutral_element):\n",
    "        \"\"\"Build a Segment Tree data structure.\n",
    "        https://en.wikipedia.org/wiki/Segment_tree\n",
    "        Can be used as regular array, but with two\n",
    "        important differences:\n",
    "            a) setting item's value is slightly slower.\n",
    "               It is O(lg capacity) instead of O(1).\n",
    "            b) user has access to an efficient ( O(log segment size) )\n",
    "               `reduce` operation which reduces `operation` over\n",
    "               a contiguous subsequence of items in the array.\n",
    "        Paramters\n",
    "        ---------\n",
    "        capacity: int\n",
    "            Total size of the array - must be a power of two.\n",
    "        operation: lambda obj, obj -> obj\n",
    "            and operation for combining elements (eg. sum, max)\n",
    "            must form a mathematical group together with the set of\n",
    "            possible values for array elements (i.e. be associative)\n",
    "        neutral_element: obj\n",
    "            neutral element for the operation above. eg. float('-inf')\n",
    "            for max and 0 for sum.\n",
    "        \"\"\"\n",
    "        assert capacity > 0 and capacity & (capacity - 1) == 0, \"capacity must be positive and a power of 2.\"\n",
    "        self._capacity = capacity\n",
    "        self._value = [neutral_element for _ in range(2 * capacity)]\n",
    "        self._operation = operation\n",
    "\n",
    "    def _reduce_helper(self, start, end, node, node_start, node_end):\n",
    "        if start == node_start and end == node_end:\n",
    "            return self._value[node]\n",
    "        mid = (node_start + node_end) // 2\n",
    "        if end <= mid:\n",
    "            return self._reduce_helper(start, end, 2 * node, node_start, mid)\n",
    "        else:\n",
    "            if mid + 1 <= start:\n",
    "                return self._reduce_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
    "            else:\n",
    "                return self._operation(\n",
    "                    self._reduce_helper(start, mid, 2 * node, node_start, mid),\n",
    "                    self._reduce_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end)\n",
    "                )\n",
    "\n",
    "    def reduce(self, start=0, end=None):\n",
    "        \"\"\"Returns result of applying `self.operation`\n",
    "        to a contiguous subsequence of the array.\n",
    "            self.operation(arr[start], operation(arr[start+1], operation(... arr[end])))\n",
    "        Parameters\n",
    "        ----------\n",
    "        start: int\n",
    "            beginning of the subsequence\n",
    "        end: int\n",
    "            end of the subsequences\n",
    "        Returns\n",
    "        -------\n",
    "        reduced: obj\n",
    "            result of reducing self.operation over the specified range of array elements.\n",
    "        \"\"\"\n",
    "        if end is None:\n",
    "            end = self._capacity\n",
    "        if end < 0:\n",
    "            end += self._capacity\n",
    "        end -= 1\n",
    "        return self._reduce_helper(start, end, 1, 0, self._capacity - 1)\n",
    "\n",
    "    def __setitem__(self, idx, val):\n",
    "        # index of the leaf\n",
    "        idx += self._capacity\n",
    "        self._value[idx] = val\n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self._value[idx] = self._operation(\n",
    "                self._value[2 * idx],\n",
    "                self._value[2 * idx + 1]\n",
    "            )\n",
    "            idx //= 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < self._capacity\n",
    "        return self._value[self._capacity + idx]\n",
    "\n",
    "\n",
    "class SumSegmentTree(SegmentTree):\n",
    "    def __init__(self, capacity):\n",
    "        super(SumSegmentTree, self).__init__(\n",
    "            capacity=capacity,\n",
    "            operation=operator.add,\n",
    "            neutral_element=0.0\n",
    "        )\n",
    "\n",
    "    def sum(self, start=0, end=None):\n",
    "        \"\"\"Returns arr[start] + ... + arr[end]\"\"\"\n",
    "        return super(SumSegmentTree, self).reduce(start, end)\n",
    "\n",
    "    def find_prefixsum_idx(self, prefixsum):\n",
    "        \"\"\"Find the highest index `i` in the array such that\n",
    "            sum(arr[0] + arr[1] + ... + arr[i - i]) <= prefixsum\n",
    "        if array values are probabilities, this function\n",
    "        allows to sample indexes according to the discrete\n",
    "        probability efficiently.\n",
    "        Parameters\n",
    "        ----------\n",
    "        perfixsum: float\n",
    "            upperbound on the sum of array prefix\n",
    "        Returns\n",
    "        -------\n",
    "        idx: int\n",
    "            highest index satisfying the prefixsum constraint\n",
    "        \"\"\"\n",
    "        assert 0 <= prefixsum <= self.sum() + 1e-5\n",
    "        idx = 1\n",
    "        while idx < self._capacity:  # while non-leaf\n",
    "            if self._value[2 * idx] > prefixsum:\n",
    "                idx = 2 * idx\n",
    "            else:\n",
    "                prefixsum -= self._value[2 * idx]\n",
    "                idx = 2 * idx + 1\n",
    "        return idx - self._capacity\n",
    "\n",
    "\n",
    "class MinSegmentTree(SegmentTree):\n",
    "    def __init__(self, capacity):\n",
    "        super(MinSegmentTree, self).__init__(\n",
    "            capacity=capacity,\n",
    "            operation=min,\n",
    "            neutral_element=float('inf')\n",
    "        )\n",
    "\n",
    "    def min(self, start=0, end=None):\n",
    "        \"\"\"Returns min(arr[start], ...,  arr[end])\"\"\"\n",
    "\n",
    "        return super(MinSegmentTree, self).reduce(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:47.265452Z",
     "start_time": "2020-12-14T14:52:47.249262Z"
    }
   },
   "outputs": [],
   "source": [
    "''' PER Replaybuffer '''\n",
    "\n",
    "import numpy as np\n",
    "#from segment_tree import MinSegmentTree, SumSegmentTree # This is baseline provided in OpenAI.\n",
    "\n",
    "# Naive ReplayBuffer\n",
    "class ReplayBuffer:\n",
    "    \"\"\" Experience Replay Buffer which is implemented in DQN paper. https://www.nature.com/articles/nature14236 \n",
    "    The detailed parameter is described in each method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 buffer_size: ('int: total size of the Replay Buffer'), \n",
    "                 input_dim: ('int: a dimension of input data'),\n",
    "                 action_dim: ('int: a dimension of action'),\n",
    "                 batch_size: ('int: a batch size when updating')):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        self.save_count, self.current_size = 0, 0\n",
    "\n",
    "        self.state_buffer = np.ones((buffer_size, input_dim), dtype=np.float32) \n",
    "        self.action_buffer = np.ones((buffer_size, action_dim), dtype=np.float32) \n",
    "        self.reward_buffer = np.ones(buffer_size, dtype=np.float32) \n",
    "        self.next_state_buffer = np.ones((buffer_size, input_dim), dtype=np.float32) \n",
    "        self.done_buffer = np.ones(buffer_size, dtype=np.int8)  \n",
    "\n",
    "    def store(self, \n",
    "              state: np.float32, \n",
    "              action: np.float32, \n",
    "              reward: np.float32, \n",
    "              next_state: np.float32, \n",
    "              done: np.int8):\n",
    "\n",
    "        self.state_buffer[self.save_count] = state\n",
    "        self.action_buffer[self.save_count] = action\n",
    "        self.reward_buffer[self.save_count] = reward\n",
    "        self.next_state_buffer[self.save_count] = next_state\n",
    "        self.done_buffer[self.save_count] = done\n",
    "\n",
    "        self.save_count = (self.save_count + 1) % self.buffer_size\n",
    "        self.current_size = min(self.current_size+1, self.buffer_size)\n",
    "\n",
    "    def batch_load(self):\n",
    "        indices = np.random.randint(self.current_size, size=self.batch_size)\n",
    "        return dict(\n",
    "                states=self.state_buffer[indices], \n",
    "                actions=self.action_buffer[indices],\n",
    "                rewards=self.reward_buffer[indices],\n",
    "                next_states=self.next_state_buffer[indices], \n",
    "                dones=self.done_buffer[indices]) \n",
    "\n",
    "# ReplayBuffer for Prioritized Experience Replay. \n",
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \n",
    "    def __init__(self, buffer_size, input_dim, action_dim, batch_size, alpha):\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(buffer_size, input_dim, action_dim, batch_size)\n",
    "        \n",
    "        # For PER. Parameter settings. \n",
    "        self.max_priority, self.tree_idx = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.buffer_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(self, \n",
    "              state: np.float32, \n",
    "              action: np.float32, \n",
    "              reward: np.float32, \n",
    "              next_state: np.ndarray, \n",
    "              done: np.int8):\n",
    "        \n",
    "        super().store(state, action, reward, next_state, done)\n",
    "        \n",
    "        self.sum_tree[self.tree_idx] = self.max_priority ** self.alpha\n",
    "        self.min_tree[self.tree_idx] = self.max_priority ** self.alpha\n",
    "        self.tree_idx = (self.tree_idx + 1) % self.buffer_size\n",
    "\n",
    "    def batch_load(self, beta):\n",
    "        \n",
    "        indices, p_total = self._sample_indices_with_priority()\n",
    "        weights = self._cal_weight(indices, p_total, self.current_size, beta)\n",
    "        return dict(\n",
    "                states=self.state_buffer[indices], \n",
    "                actions=self.action_buffer[indices],\n",
    "                rewards=self.reward_buffer[indices],\n",
    "                next_states=self.next_state_buffer[indices], \n",
    "                dones=self.done_buffer[indices],\n",
    "                weights=weights,\n",
    "                indices=indices) \n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \n",
    "        for idx, priority in zip(indices, priorities.flatten()):\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "            \n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "    \n",
    "    def _sample_indices_with_priority(self):\n",
    "\n",
    "        p_total = self.sum_tree.sum() \n",
    "        segment = p_total / self.batch_size\n",
    "        segment_list = [i*segment for i in range(self.batch_size)]\n",
    "        samples = [np.random.uniform(a, a+segment) for a in segment_list]\n",
    "        indices = [self.sum_tree.find_prefixsum_idx(sample) for sample in samples]\n",
    "        \n",
    "        return indices, p_total\n",
    "    \n",
    "    def _cal_weight(self, indices, p_total, N, beta):\n",
    "        \n",
    "        p_min = self.min_tree.min() / p_total\n",
    "        max_weight = (p_min*N) ** (-beta) \n",
    "        \n",
    "        p_samples = np.array([self.sum_tree[idx] for idx in indices]) / p_total\n",
    "        weights = (p_samples*N)**(-beta)/max_weight\n",
    "        return weights\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    buffer_size = 100\n",
    "    input_dim = 300\n",
    "    action_dim = 100\n",
    "    batch_size = 16\n",
    "    alpha = 0.6\n",
    "    beta = 0.4\n",
    "    buffer = PrioritizedReplayBuffer(buffer_size, input_dim, action_dim, batch_size, alpha)\n",
    "    for i in range(50):\n",
    "        state = np.ones(input_dim)\n",
    "        action = 1\n",
    "        reward = 1\n",
    "        next_state = np.ones(input_dim)\n",
    "        done = 1\n",
    "        buffer.store(state, action, reward, next_state, done)\n",
    "    '''\n",
    "    print(buffer.alpha)\n",
    "    print(buffer.max_priority)\n",
    "    print(buffer.batch_load(beta)['states'].shape)\n",
    "    print(buffer.batch_load(beta)['actions'].shape)\n",
    "    print(buffer.batch_load(beta)['rewards'].shape)\n",
    "    print(buffer.batch_load(beta)['next_states'].shape)\n",
    "    print(buffer.batch_load(beta)['dones'].shape)\n",
    "    print(buffer.batch_load(beta)['weights'].shape)\n",
    "    print(buffer.batch_load(beta)['indices'].__len__())\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:48.463493Z",
     "start_time": "2020-12-14T14:52:48.460994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstate = drrave_state_rep(userid_b,item_b,memory,idx_b)\\nstate_rep =  torch.reshape(state,[-1])\\nnext_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\\nnext_state_rep = torch.reshape(next_state,[-1])\\n#R.push(state_rep.detach().cpu().numpy(), action_emb.detach().cpu().numpy(), reward, next_state_rep.detach().cpu().numpy()\\n)\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "state_rep =  torch.reshape(state,[-1])\n",
    "next_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "next_state_rep = torch.reshape(next_state,[-1])\n",
    "#R.push(state_rep.detach().cpu().numpy(), action_emb.detach().cpu().numpy(), reward, next_state_rep.detach().cpu().numpy()\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:49.023798Z",
     "start_time": "2020-12-14T14:52:49.022039Z"
    }
   },
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:49.382929Z",
     "start_time": "2020-12-14T14:52:49.381239Z"
    }
   },
   "outputs": [],
   "source": [
    "#used for plotting purposes\n",
    "p_loss = []\n",
    "v_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:28:49.483640Z",
     "start_time": "2020-12-14T14:28:49.481505Z"
    }
   },
   "source": [
    "DDPG Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:50.599081Z",
     "start_time": "2020-12-14T14:52:50.590497Z"
    }
   },
   "outputs": [],
   "source": [
    "def ddpg_update(batch_size=32, \n",
    "                gamma = 0.6,\n",
    "                min_value=-np.inf,\n",
    "                max_value=np.inf,\n",
    "                soft_tau=1e-2,\n",
    "                beta=0.4):\n",
    "    \n",
    "    batch = replay_buffer.batch_load(beta)\n",
    "    weights = torch.FloatTensor(batch['weights'].reshape(-1, 1)).to(device) # device 는 GPU 번호\n",
    "    states = torch.FloatTensor(batch['states']).to(device)\n",
    "    next_states = torch.FloatTensor(batch['next_states']).to(device)\n",
    "    actions = torch.FloatTensor(batch['actions']).to(device)\n",
    "    rewards = torch.FloatTensor(batch['rewards'].reshape(-1, 1)).to(device)\n",
    "    dones = torch.FloatTensor(batch['dones'].reshape(-1, 1)).to(device)\n",
    "    \n",
    "    # policy loss\n",
    "    policy_loss = -(weights * value_net(states, policy_net(states))).mean()\n",
    "    p_loss.append(policy_loss) \n",
    "    \n",
    "    # value loss\n",
    "    # print(states.shape)\n",
    "    # print(actions.shape)\n",
    "    value = value_net(states, actions)\n",
    "    next_actions   = target_policy_net(next_states) \n",
    "    mask = 1 - dones\n",
    "    expected_value = (rewards + gamma * mask * target_value_net(next_states, next_actions.detach())).to(device) \n",
    "    expected_value = torch.clamp(expected_value, min_value, max_value) \n",
    "    sample_wise_loss = F.smooth_l1_loss(value, expected_value.detach(), reduction=\"none\") \n",
    "        \n",
    "    value_loss = (weights * sample_wise_loss).mean()\n",
    "    v_loss.append(value_loss)\n",
    "    \n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "    \n",
    "    # For PER: update priorities of the samples.\n",
    "    epsilon_for_priority = 1e-8\n",
    "    sample_wise_loss = sample_wise_loss.detach().cpu().numpy()\n",
    "    batch_priorities = sample_wise_loss + epsilon_for_priority\n",
    "    replay_buffer.update_priorities(batch['indices'], batch_priorities)\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - soft_tau) + param.data * soft_tau)\n",
    "\n",
    "    for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - soft_tau) + param.data * soft_tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:51.514096Z",
     "start_time": "2020-12-14T14:52:51.512197Z"
    }
   },
   "outputs": [],
   "source": [
    "# #initializing actor and critic networks for drru and drrp state representation\n",
    "\n",
    "# value_net = Critic(5500,100,256).to(device)\n",
    "# policy_net = Actor(5500,100,256).to(device)\n",
    "\n",
    "# target_value_net = Critic(5500,100,256).to(device)\n",
    "# target_policy_net = Actor(5500,100,256).to(device)\n",
    "\n",
    "    \n",
    "# target_policy_net.eval()\n",
    "# target_value_net.eval()\n",
    "\n",
    "# for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "#     target_param.data.copy_(param.data)\n",
    "\n",
    "# for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "#     target_param.data.copy_(param.data)\n",
    "\n",
    "# value_criterion = nn.MSELoss()\n",
    "# value_optimizer      = Ranger(value_net.parameters(),  lr=1e-4)\n",
    "# policy_optimizer     = Ranger(policy_net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:53.691797Z",
     "start_time": "2020-12-14T14:52:53.672114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      "Current version (0.1.0)  1e-16  True               True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      "Current version (0.1.0)  1e-16  True               True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Rectification enabled in AdaBelief\n"
     ]
    }
   ],
   "source": [
    "#initializing for drrave state representation\n",
    "\n",
    "value_net = Critic(300,100,256).to(device)\n",
    "policy_net = Actor(300,100,256).to(device)\n",
    "\n",
    "target_value_net = Critic(300,100,256).to(device)\n",
    "target_policy_net = Actor(300,100,256).to(device)\n",
    "\n",
    "target_policy_net.eval()\n",
    "target_value_net.eval()\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "value_criterion = nn.MSELoss()\n",
    "value_optimizer = AdaBelief(value_net.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True)\n",
    "policy_optimizer = AdaBelief(policy_net.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:52:55.375606Z",
     "start_time": "2020-12-14T14:52:55.285018Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer_size = 100000\n",
    "replay_buffer = PrioritizedReplayBuffer(buffer_size, input_dim, action_dim, batch_size, alpha)\n",
    "memory = np.ones((train_num,10))*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:01.859731Z",
     "start_time": "2020-12-14T14:53:01.857961Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.sort??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:02.178151Z",
     "start_time": "2020-12-14T14:53:02.174608Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_action(state, action_emb, userid_b, items):\n",
    "    action_emb = torch.reshape(action_emb,[1,100]).unsqueeze(0).to(device)\n",
    "    m = torch.bmm(action_emb,items).squeeze(0)  #torch.bmm : batch 행렬 곱연산\n",
    "    _, indices = torch.sort(m, descending=True)\n",
    "    index_list = list(indices[0])\n",
    "    for i in index_list: \n",
    "        if users_dict[int(userid_b[0])][\"item\"][i] not in preds:     \n",
    "            preds.add(users_dict[int(userid_b[0])][\"item\"][i]) \n",
    "            return int(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:02.380558Z",
     "start_time": "2020-12-14T14:53:02.378709Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_memory(memory,action,idx):\n",
    "    memory[idx] = list(memory[idx,1:])+[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:02.537596Z",
     "start_time": "2020-12-14T14:53:02.535998Z"
    }
   },
   "outputs": [],
   "source": [
    "rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:02.989051Z",
     "start_time": "2020-12-14T14:53:02.985532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([83140]), tensor([242400]), tensor([272815]), tensor([386879]), tensor([388069]), tensor([388982]), tensor([390076]), tensor([390771]), tensor([392444]), tensor([392541])]\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "first = next(it)\n",
    "item_b,rating_b,size_b,userid_b,idx_b = first['item'],first['rating'],first['size'],first['userid'],first['idx']\n",
    "print(item_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:03.436569Z",
     "start_time": "2020-12-14T14:53:03.433116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([522451]), tensor([778033]), tensor([783221]), tensor([809749]), tensor([809678]), tensor([898871]), tensor([899931]), tensor([972851]), tensor([522448]), tensor([522410])]\n"
     ]
    }
   ],
   "source": [
    "first = next(it)\n",
    "item_b,rating_b,size_b,userid_b,idx_b = first['item'],first['rating'],first['size'],first['userid'],first['idx']\n",
    "print(item_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:03.777903Z",
     "start_time": "2020-12-14T14:53:03.774711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([4]),\n",
       " tensor([5]),\n",
       " tensor([5]),\n",
       " tensor([5]),\n",
       " tensor([5]),\n",
       " tensor([5]),\n",
       " tensor([4]),\n",
       " tensor([4]),\n",
       " tensor([5]),\n",
       " tensor([4])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:04.115484Z",
     "start_time": "2020-12-14T14:53:04.113050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10110561\n"
     ]
    }
   ],
   "source": [
    "print(int(userid_b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:04.518673Z",
     "start_time": "2020-12-14T14:53:04.516649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([778033])\n"
     ]
    }
   ],
   "source": [
    "print(item_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:04.893450Z",
     "start_time": "2020-12-14T14:53:04.879414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[522451. 778033. 783221. 809749. 809678. 898871. 899931. 972851. 522448.\n",
      " 522410.]\n"
     ]
    }
   ],
   "source": [
    "memory = np.ones((train_num,10))*-1\n",
    "memory[idx_b] = [item[0] for item in item_b]\n",
    "print(memory[idx_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:05.201096Z",
     "start_time": "2020-12-14T14:53:05.199051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(778033)\n"
     ]
    }
   ],
   "source": [
    "print(item_b[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:05.517727Z",
     "start_time": "2020-12-14T14:53:05.515401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00000e+00 -1.00000e+00 -1.00000e+00 ... -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00]\n",
      " [ 5.22451e+05  7.78033e+05  7.83221e+05 ...  9.72851e+05  5.22448e+05\n",
      "   5.22410e+05]\n",
      " [-1.00000e+00 -1.00000e+00 -1.00000e+00 ... -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00]\n",
      " ...\n",
      " [-1.00000e+00 -1.00000e+00 -1.00000e+00 ... -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00]\n",
      " [-1.00000e+00 -1.00000e+00 -1.00000e+00 ... -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00]\n",
      " [-1.00000e+00 -1.00000e+00 -1.00000e+00 ... -1.00000e+00 -1.00000e+00\n",
      "  -1.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:05.855233Z",
     "start_time": "2020-12-14T14:53:05.853210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(idx_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENV & ou_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:06.609585Z",
     "start_time": "2020-12-14T14:53:06.599003Z"
    }
   },
   "outputs": [],
   "source": [
    "class OfflineEnv:\n",
    "\n",
    "    def __init__(self, dataloader, users_dict, item_embeddings_dict):\n",
    "        \n",
    "        self.dataloader = iter(dataloader)\n",
    "        self.users_dict = users_dict\n",
    "        \n",
    "        self.data = next(self.dataloader) # {'item':items,'rating':ratings,'size':size,'userid':user_id,'idx':idx}\n",
    "        self.user_history = self.users_dict[int(self.data['userid'])]\n",
    "        \n",
    "        self.item_embedding = torch.Tensor([np.array(item_embeddings_dict[item]) for item in users_dict[int(self.data['userid'][0])]['item']])\n",
    "        self.items = self.item_embedding.T.unsqueeze(0)\n",
    "\n",
    "        self.memory = [item[0] for item in self.data['item']]\n",
    "        self.done = 0\n",
    "\n",
    "        self.related_books = self.generate_related_books()\n",
    "        self.viewed_pos_books = []\n",
    "    \n",
    "    def generate_related_books(self):\n",
    "        related_movie = []\n",
    "        items = self.user_history['item'][10:]\n",
    "        ratings = self.user_history['rating'][10:]\n",
    "\n",
    "        for item, rating in zip(items, ratings):\n",
    "            if rating > 3:\n",
    "                related_movie.append(item)\n",
    "        \n",
    "        return related_movie\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = next(self.dataloader)\n",
    "        self.memory = [item[0] for item in self.data['item']]\n",
    "        self.user_history = self.users_dict[int(self.data['userid'])]\n",
    "        self.done = 0\n",
    "        self.item_embedding = torch.Tensor([np.array(item_embeddings_dict[item]) for item in users_dict[int(self.data['userid'][0])]['item']])\n",
    "        self.items = self.item_embedding.T.unsqueeze(0)\n",
    "        self.related_books = self.generate_related_books()\n",
    "        self.viewed_pos_books = []\n",
    "\n",
    "    def update_memory(self,action):\n",
    "        self.memory = list(self.memory[1:]) + [self.user_history['item'][action]]\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        ### Env : step\n",
    "        ### \n",
    "        rating = int(self.user_history[\"rating\"][action])\n",
    "        normal_rating = (int(rating)-3)/2\n",
    "        reward = torch.Tensor((normal_rating,))\n",
    "        #ep_reward = ep_reward + ratings\n",
    "\n",
    "        if reward > 0:\n",
    "            self.update_memory(action)\n",
    "            self.viewed_pos_books.append(action)\n",
    "    \n",
    "        if len(self.viewed_pos_books) == len(self.related_books):\n",
    "            self.done = 1\n",
    "        \n",
    "        return self.memory, reward, self.done\n",
    "\n",
    "\n",
    "        #next_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "        #next_state_rep = torch.reshape(next_state,[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:07.098182Z",
     "start_time": "2020-12-14T14:53:07.092715Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import torch.utils.data as td\n",
    "\n",
    "#https://github.com/vitchyr/rlkit/blob/master/rlkit/exploration_strategies/ou_strategy.py\n",
    "class OUNoise(object):\n",
    "    def __init__(self, action_dim, mu=0.0, theta=0.15, max_sigma=0.4, min_sigma=0.4, decay_period=100000):\n",
    "        self.mu           = mu\n",
    "        self.theta        = theta\n",
    "        self.sigma        = max_sigma\n",
    "        self.max_sigma    = max_sigma\n",
    "        self.min_sigma    = min_sigma\n",
    "        self.decay_period = decay_period\n",
    "        self.action_dim   = action_dim\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.ones(self.action_dim) * self.mu\n",
    "\n",
    "    def evolve_state(self):\n",
    "        x  = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "    def get_action(self, action, t=0):\n",
    "        ou_state = self.evolve_state()\n",
    "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
    "        return torch.tensor([action + ou_state]).float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:08.347903Z",
     "start_time": "2020-12-14T14:53:08.345886Z"
    }
   },
   "outputs": [],
   "source": [
    "# OfflineEnv??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:08.754985Z",
     "start_time": "2020-12-14T14:53:08.753095Z"
    }
   },
   "outputs": [],
   "source": [
    "ou_noise = OUNoise(100, decay_period=10)\n",
    "params = {\n",
    "    'ou_noise': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:09.213802Z",
     "start_time": "2020-12-14T14:53:09.205175Z"
    }
   },
   "outputs": [],
   "source": [
    "class OfflineEnv2:\n",
    "\n",
    "    def __init__(self, dataloader, users_dict, item_embeddings_dict):\n",
    "        \n",
    "        self.dataloader = iter(dataloader)\n",
    "        self.users_dict = users_dict\n",
    "        \n",
    "        self.data = next(self.dataloader) # {'item':items,'rating':ratings,'size':size,'userid':user_id,'idx':idx}\n",
    "        self.user_history = self.users_dict[int(self.data['userid'])]\n",
    "        \n",
    "        self.item_embedding = torch.Tensor([np.array(item_embeddings_dict[item]) for item in users_dict[int(self.data['userid'][0])]['item']])\n",
    "        self.items = self.item_embedding.T.unsqueeze(0)\n",
    "\n",
    "        self.memory = [item[0] for item in self.data['item']]\n",
    "        self.done = 0\n",
    "\n",
    "        self.related_books = self.generate_related_books()\n",
    "        self.viewed_pos_books = []\n",
    "    \n",
    "    def generate_related_books(self):\n",
    "        related_movie = []\n",
    "        items = self.user_history['item'][10:]\n",
    "        ratings = self.user_history['rating'][10:]\n",
    "\n",
    "        for item, rating in zip(items, ratings):\n",
    "            if rating > 3:\n",
    "                related_movie.append(item)\n",
    "        \n",
    "        return related_movie\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = next(self.dataloader)\n",
    "        self.memory = [item[0] for item in self.data['item']]\n",
    "        self.user_history = self.users_dict[int(self.data['userid'])]\n",
    "        self.done = 0\n",
    "        self.item_embedding = torch.Tensor([np.array(item_embeddings_dict[item]) for item in users_dict[int(self.data['userid'][0])]['item']])\n",
    "        self.items = self.item_embedding.T.unsqueeze(0)\n",
    "        self.related_books = self.generate_related_books()\n",
    "        self.viewed_pos_books = []\n",
    "\n",
    "    def update_memory(self,action):\n",
    "        self.memory = list(self.memory[1:]) + [self.user_history['item'][action]]\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        ### Env : step\n",
    "        ### \n",
    "        rating = int(self.user_history[\"rating\"][action])\n",
    "        normal_rating = (int(rating)-3)/2\n",
    "        reward = torch.Tensor((normal_rating,))\n",
    "        #ep_reward = ep_reward + ratings\n",
    "\n",
    "        if reward > 0:\n",
    "            self.update_memory(action)\n",
    "            self.viewed_pos_books.append(action)\n",
    "    \n",
    "        if len(self.viewed_pos_books) == len(self.related_books):\n",
    "            self.done = 1\n",
    "        \n",
    "        return self.memory, reward, self.done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:53:17.653356Z",
     "start_time": "2020-12-14T14:53:10.371464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 163/189081 [00:07<2:20:04, 22.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-7bf60d835ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                 reward, next_state_rep.detach().cpu().numpy(), done)\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mddpg_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-7f35b130e26a>\u001b[0m in \u001b[0;36mddpg_update\u001b[0;34m(batch_size, gamma, min_value, max_value, soft_tau, beta)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mvalue_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mvalue_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mvalue_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = OfflineEnv2(train_dataloader, users_dict, item_embeddings_dict)\n",
    "preddict = dict()\n",
    "accum_rewards = []\n",
    "for episode in tqdm.tqdm(range(train_num-1)):\n",
    "    ep_reward = 0\n",
    "    batch_size= 8\n",
    "\n",
    "    item_b, rating_b, size_b, userid_b, idx_b = env.data['item'], env.data['rating'], env.data['size'], env.data['userid'], env.data['idx']\n",
    "    memory = env.memory\n",
    "    preds = set(item_b)\n",
    "    state = drrave_state_rep(userid_b,memory,idx_b)\n",
    "    items = env.items.to(device)\n",
    "    \n",
    "    done = 0\n",
    "    user_len = len(env.user_history['item'])\n",
    "    # print(\"User Length\", user_len)\n",
    "\n",
    "    # 만약 추처할 대상이 없다면\n",
    "    if len(env.user_history['rating']) == len(preds):\n",
    "        continue\n",
    "\n",
    "    # 5개만 추천하기\n",
    "    for j in range(5):\n",
    "        if done == 0:\n",
    "            state_rep =  torch.reshape(state,[-1])\n",
    "            action_emb = policy_net(state_rep)\n",
    "            \n",
    "            if params['ou_noise']:\n",
    "                action_emb = ou_noise.get_action(action_emb.detach().cpu().numpy()[0], j)\n",
    "                action_emb = action_emb.squeeze(0)\n",
    "            action = get_action(state, action_emb, userid_b, items)\n",
    "            \n",
    "            memory, reward, done = env.step(action)\n",
    "        \n",
    "            ep_reward += reward\n",
    "            next_state = drrave_state_rep(userid_b, memory, idx_b)\n",
    "            next_state_rep = torch.reshape(next_state,[-1])\n",
    "\n",
    "            replay_buffer.store(state_rep.detach().cpu().numpy(), \n",
    "                                action_emb.detach().cpu().numpy(), \n",
    "                                reward, next_state_rep.detach().cpu().numpy(), done)\n",
    "            if replay_buffer.current_size > batch_size:\n",
    "                ddpg_update(batch_size=batch_size)\n",
    "\n",
    "            state = next_state\n",
    "        else:\n",
    "            break\n",
    "    env.reset()\n",
    "    accum_rewards.append(ep_reward)\n",
    "    preddict[userid_b[0]] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T14:42:38.290160Z",
     "start_time": "2020-12-14T14:42:38.108095Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-09a1f871e2a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "len(env.user_history['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor(4331406): {70276, 214356, 1391900, 2087086, 2498016},\n",
       " tensor(6717064): {2451670, 2465149, 2467158, 2471290, 2473794},\n",
       " tensor(1453186): {481794, 572572, 1162759, 1246217, 1593841},\n",
       " tensor(13746747): {196585, 197029, 197142, 198279, 2350592},\n",
       " tensor(12694617): {217072, 346067, 568990, 1674352, 2426519},\n",
       " tensor(12043813): {4266, 4689, 4844, 5437, 5902},\n",
       " tensor(7273102): {9770, 16688, 198716, 221579, 2719031},\n",
       " tensor(10077243): {1253013, 1569142, 1630879, 1738338, 1824579},\n",
       " tensor(13930480): {1856734, 2451670, 2453028, 2456229, 2456819},\n",
       " tensor(7836930): {1835140, 1849476, 2452924, 2461402, 2461946},\n",
       " tensor(11772633): {215711, 215713, 299006, 317365, 823298},\n",
       " tensor(2672556): {9770, 1569295, 1609389, 1616882, 2719031},\n",
       " tensor(1181767): {116144, 142283, 522654, 1556227, 1754966},\n",
       " tensor(9949838): {1569128, 1569228, 1569232, 1698923, 2438129},\n",
       " tensor(7391975): {284339, 678573, 1335215, 1463079, 1709433},\n",
       " tensor(13524533): {92502, 194278, 203097, 649014, 671984},\n",
       " tensor(593966): {285231, 583049, 619822, 1821923, 2422745},\n",
       " tensor(325864): {498150, 1570033, 1608584, 1689306, 1791375},\n",
       " tensor(13609319): {106927, 284498, 1569004, 2145514, 2925109},\n",
       " tensor(10698704): {526916, 1201338, 1451557, 1880403, 1938512},\n",
       " tensor(3844461): {72530, 97103, 134673, 241806, 852814},\n",
       " tensor(5228796): {457421, 709445, 833207, 834027, 1876664},\n",
       " tensor(7080661): {101652, 426482, 920105, 2057060, 2260382},\n",
       " tensor(1491627): {494803, 1263382, 1263383, 1593161, 1856367},\n",
       " tensor(8345666): {97369, 1377132, 1445984, 1611797, 2098716},\n",
       " tensor(880955): {18318, 69167, 102082, 1607000, 2153967},\n",
       " tensor(8433075): {3019, 146801, 427356, 486550, 1055466},\n",
       " tensor(14597616): {497383, 503325, 1579727, 1667451, 2027963},\n",
       " tensor(14076010): {255397, 328628, 346800, 1587977, 2045470},\n",
       " tensor(1902751): {97389, 115300, 169959, 577846, 2912475},\n",
       " tensor(13633933): {199060, 789693, 1194165, 2418507, 2787746},\n",
       " tensor(3534616): {486427, 728167, 1287811, 1457094, 1940743},\n",
       " tensor(9577437): {237576, 237594, 962301, 1134556, 1798627},\n",
       " tensor(3018619): {550991, 1219341, 1249089, 1598965, 1602709},\n",
       " tensor(3123765): {253466, 1802959, 2008693, 2458219, 2830455},\n",
       " tensor(9857898): {19968, 196461, 274674, 326630, 1526792},\n",
       " tensor(538605): {48355, 48647, 366276, 1309630, 2398788},\n",
       " tensor(2292497): {581622, 1686182, 1711145, 1783619, 1847318},\n",
       " tensor(2073829): {743168, 791020, 2082146, 2082263, 2591457},\n",
       " tensor(14091131): {1056024, 1120206, 1405152, 2065785, 2916002},\n",
       " tensor(10790772): {608800, 1468829, 2207578, 2221596, 2350592},\n",
       " tensor(8670549): {203097, 1246107, 1859576, 2052217, 2295422},\n",
       " tensor(9289869): {42032, 93122, 262813, 274920, 515267},\n",
       " tensor(10765394): {1677830, 1697548, 1747798, 1784126, 2469797},\n",
       " tensor(14583640): {575825, 584331, 1695871, 1745289, 2069491},\n",
       " tensor(13462237): {563774, 703277, 1629328, 2012084, 2273446},\n",
       " tensor(11785117): {233500, 245452, 299467, 609849, 1620438},\n",
       " tensor(2977239): {1515832, 1557218, 1569174, 1616687, 1715209},\n",
       " tensor(7080849): {574276, 1571520, 1773378, 1793131, 2470221},\n",
       " tensor(10609453): {18511, 23002, 69756, 185101, 2209806},\n",
       " tensor(4779514): {584396, 1220984, 2481339, 2481342, 2875871},\n",
       " tensor(4397386): {43272, 45391, 168974, 1951109, 2003519},\n",
       " tensor(14478995): {757945, 1509896, 1569290, 1813152, 2325764},\n",
       " tensor(423057): {1241976, 1788418, 1822694, 2433797, 2889743},\n",
       " tensor(10745610): {746441, 1858353, 2349449, 2350599, 2921888},\n",
       " tensor(3966161): {954871, 1400422, 2103431, 2220634, 2259487},\n",
       " tensor(4998592): {664097, 1118908, 1236213, 1698881, 2219657},\n",
       " tensor(7237840): {1262863, 1674790, 1702047, 1707189, 1739239},\n",
       " tensor(12829425): {35511, 717175, 1939185, 1975285, 2090325},\n",
       " tensor(11365896): {137068, 297117, 397880, 699163, 800371},\n",
       " tensor(6943603): {1378382, 1556098, 1568270, 2826606, 2873942},\n",
       " tensor(7703436): {220114, 1224485, 1249449, 1551532, 1843956},\n",
       " tensor(11236843): {177099, 294353, 531520, 664099, 1820204},\n",
       " tensor(5689680): {115050, 215992, 216662, 1028437, 2514299},\n",
       " tensor(9683696): {81211, 138415, 1158609, 1601258, 2533268},\n",
       " tensor(7596379): {18229, 345095, 439332, 1238274, 1307821},\n",
       " tensor(6573986): {757128, 757268, 757819, 2311984, 2311995},\n",
       " tensor(10692610): {291795, 310236, 347711, 360106, 748003},\n",
       " tensor(12715136): {218056, 1715183, 2347140, 2876036, 2888748},\n",
       " tensor(7921808): {1292619, 1473052, 2130636, 2216443, 2217201},\n",
       " tensor(4176348): {730754, 1391281, 1551880, 1698756, 1699482},\n",
       " tensor(8785884): {6837, 328528, 1723013, 1851412, 2478027},\n",
       " tensor(681860): {255310, 1752156, 2160350, 2160399, 2445207},\n",
       " tensor(5034399): {1761923, 1853137, 2451873, 2468627, 2480580},\n",
       " tensor(14339643): {23002, 535091, 664097, 2666075, 2913473},\n",
       " tensor(12773349): {94757, 105151, 388790, 605411, 2268184},\n",
       " tensor(1323881): {328628, 359974, 1541051, 1662691, 1672486},\n",
       " tensor(7131086): {33627, 216267, 504256, 1272494, 1596336},\n",
       " tensor(12840330): {1127412, 1217403, 1603283, 1623614, 2343040},\n",
       " tensor(9780716): {1599008, 1603283, 1609389, 1614728, 1680914},\n",
       " tensor(13840226): {1059854, 1094559, 1099206, 1912159, 2306822},\n",
       " tensor(14781267): {757905, 757929, 1077328, 1363816, 1437573},\n",
       " tensor(12891050): {1736698, 1745586, 1757045, 1758974, 1809150},\n",
       " tensor(14103227): {18318, 24514, 94040, 278270, 347995},\n",
       " tensor(9833564): {283811, 1699534, 1699554, 2096068, 2435234},\n",
       " tensor(12873167): {576370, 1039430, 1039447, 1864610, 1986061},\n",
       " tensor(12702230): {103649, 104692, 746789, 1594151, 2171976},\n",
       " tensor(14097399): {1736, 269969, 388614, 1700677, 2150217},\n",
       " tensor(12043588): {2756, 69252, 243316, 279011, 2378186},\n",
       " tensor(8432938): {200710, 532149, 1445984, 1487381, 1487383},\n",
       " tensor(5371337): {1256609, 1783392, 1786100, 1791408, 1804440},\n",
       " tensor(14457416): {284224, 327069, 327817, 789445, 2017441},\n",
       " tensor(12950330): {1007343, 1896014, 1896059, 1896120, 1896132},\n",
       " tensor(3394389): {18318, 1983125, 1983150, 1983201, 2024654},\n",
       " tensor(3576920): {169060, 840572, 967417, 1962035, 1962315},\n",
       " tensor(3758925): {16258, 37072, 106218, 2033884, 2695054},\n",
       " tensor(12415801): {445589, 506228, 507286, 507308, 1602664},\n",
       " tensor(2302782): {185986, 189734, 678022, 810200, 810214},\n",
       " tensor(8868933): {283835, 462976, 499266, 1568970, 2197860},\n",
       " tensor(4961801): {14483, 106218, 346185, 1386464, 2695054}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190747"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:44:35.231209Z",
     "start_time": "2020-12-11T01:44:35.133125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe5e2233610>]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:44:35.515266Z",
     "start_time": "2020-12-11T01:44:35.430641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe5e21bd350>]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(p_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:03:34.183968Z",
     "start_time": "2020-12-11T01:03:34.147087Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_pred_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-30de617b82c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_embed_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtest_embed_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embed_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-30de617b82c0>\u001b[0m in \u001b[0;36mget_cosine_sim\u001b[0;34m(userid)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"item\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_pred_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#Getting Cosine similarity of recommended items for a particular userid that has been evaluated\n",
    "# from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "# import seaborn as sns\n",
    "\n",
    "def get_cosine_sim(userid):\n",
    "    test_pred = test_pred_dict[userid]\n",
    "    for i,item in enumerate(users_dict[userid][\"item\"]):\n",
    "        if item in test_pred:\n",
    "            print(item,\":\",users_dict[userid][\"rating\"][i])\n",
    "\n",
    "    test_embed = []\n",
    "    for item in test_pred:\n",
    "        test_embed.append(np.array(item_embeddings_dict[int(item)]))\n",
    "\n",
    "    test_embed_array = np.array(test_embed)\n",
    "\n",
    "    return test_embed_array\n",
    "\n",
    "test_embed_array = get_cosine_sim(userid_b[0])\n",
    "ax = sns.heatmap(cs(test_embed_array), linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.281895Z",
     "start_time": "2020-12-10T06:50:46.481Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction algorithm\n",
    "it2 = iter(test_dataloader)\n",
    "precision = 0\n",
    "test_pred_dict = dict()\n",
    "for j in range(len(test_dataloader)-1):  #session 돌리기 : timestamps 내에서 items들 \n",
    "    first = next(it2)\n",
    "    item_b,rating_b,size_b,userid_b,idx_b = first['item'],first['rating'],first['size'],first['userid'],first['idx']\n",
    "    memory[idx_b] = [item[0] for item in item_b]\n",
    "    state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "    count = 0\n",
    "    test_pred = set()\n",
    "    for j in range(5):  #policy network5번 돌리기 , 추천 5번 하기\n",
    "        state_rep =  torch.reshape(state,[-1])\n",
    "        action_emb = policy_net(state_rep)   # policy_net = actor : items들의 선호도 (rating)\n",
    "        action = get_action(state,action_emb,userid_b,item_b,test_pred)\n",
    "        rate = int(users_dict[userid_b[0]][\"rating\"][action])\n",
    "        try:\n",
    "            rating = (int(rate)-3)/2\n",
    "        except:\n",
    "            rating = 0\n",
    "        reward = torch.Tensor((rating,))\n",
    "\n",
    "        if reward > 0:\n",
    "            count += 1\n",
    "            update_memory(memory,int(users_dict[userid_b[0]][\"item\"][action]),idx_b)\n",
    "        next_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "        state = next_state\n",
    "    precision += count/5\n",
    "    test_pred_dict[userid_b[0]] = test_pred\n",
    "print(\"p\",precision/(len(test_dataloader)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.282584Z",
     "start_time": "2020-12-10T06:50:46.482Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = '/content/gdrive/My Drive/RLProject/Models/drravepolicy_net.pth'\n",
    "torch.save(policy_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.283124Z",
     "start_time": "2020-12-10T06:50:46.484Z"
    }
   },
   "outputs": [],
   "source": [
    "value_PATH = '/content/gdrive/My Drive/RLProject/Models/drravevalue_net.pth'\n",
    "torch.save(value_net.state_dict(), value_PATH)\n",
    "\n",
    "tpolicy_PATH = '/content/gdrive/My Drive/RLProject/Models/drravetpolicy_net.pth'\n",
    "torch.save(target_policy_net.state_dict(), tpolicy_PATH)\n",
    "\n",
    "tvalue_PATH = '/content/gdrive/My Drive/RLProject/Models/drravetvalue_net.pth'\n",
    "torch.save(target_value_net.state_dict(), tvalue_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.283811Z",
     "start_time": "2020-12-10T06:50:46.485Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('/content/gdrive/My Drive/RLProject/Models/train_dataloader',train_dataloader)\n",
    "np.save('/content/gdrive/My Drive/RLProject/Models/test_dataloader',test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.284614Z",
     "start_time": "2020-12-10T06:50:46.487Z"
    }
   },
   "outputs": [],
   "source": [
    "policy_net = Actor(5500,100,256)\n",
    "policy_net.load_state_dict(torch.load(PATH))\n",
    "policy_net.eval()\n",
    "\n",
    "value_net = Critic(5500,100,256)\n",
    "value_net.load_state_dict(torch.load(value_PATH))\n",
    "value_net.eval()\n",
    "\n",
    "target_policy_net = Actor(5500,100,256)\n",
    "target_policy_net.load_state_dict(torch.load(tpolicy_PATH))\n",
    "target_policy_net.eval()\n",
    "\n",
    "target_value_net = Critic(5500,100,256)\n",
    "target_value_net.load_state_dict(torch.load(tvalue_PATH))\n",
    "target_value_net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.285220Z",
     "start_time": "2020-12-10T06:50:46.488Z"
    }
   },
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "train_data = np.load('/content/gdrive/My Drive/RLProject/Models/train_users.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.285755Z",
     "start_time": "2020-12-10T06:50:46.488Z"
    }
   },
   "outputs": [],
   "source": [
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
