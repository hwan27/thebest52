{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:54:50.345009Z",
     "start_time": "2020-12-11T01:54:50.339962Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "import os \n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchtools.optim import Ranger\n",
    "from ranger import Ranger\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:52:58.160268Z",
     "start_time": "2020-12-11T00:52:55.842550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>3094405</td>\n",
       "      <td>5</td>\n",
       "      <td>1112140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>14877871</td>\n",
       "      <td>5</td>\n",
       "      <td>1466380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>7151803</td>\n",
       "      <td>5</td>\n",
       "      <td>1436400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>10069097</td>\n",
       "      <td>5</td>\n",
       "      <td>1383436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>13327705</td>\n",
       "      <td>5</td>\n",
       "      <td>1357084800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item      user  rating   timestamp\n",
       "0   122   3094405       5  1112140800\n",
       "1   122  14877871       5  1466380800\n",
       "2   122   7151803       5  1436400000\n",
       "3   122  10069097       5  1383436800\n",
       "4   122  13327705       5  1357084800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.getenv('HOME') + '/project/thebest_52/data/data_final.csv'\n",
    "columns =  ['item', 'user', 'rating', 'timestamp']\n",
    "df = pd.read_csv(datapath, sep = \",\", names = columns, dtype = int)\n",
    "df.astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:32.671567Z",
     "start_time": "2020-12-11T00:52:58.161103Z"
    }
   },
   "outputs": [],
   "source": [
    "users_df = df.sort_values([\"user\",\"timestamp\"]).set_index(\"user\").fillna(0).drop(\"timestamp\",axis=1)\n",
    "users = dict(tuple(df.groupby(\"user\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:32.674966Z",
     "start_time": "2020-12-11T00:53:32.673073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13361842, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:32.872955Z",
     "start_time": "2020-12-11T00:53:32.675878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258582"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:32.945426Z",
     "start_time": "2020-12-11T00:53:32.873974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637911"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['item'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:33.361214Z",
     "start_time": "2020-12-11T00:53:32.946258Z"
    }
   },
   "outputs": [],
   "source": [
    "# 고유한 유저, 아티스트를 찾아내는 코드\n",
    "user_unique = df['user'].unique()\n",
    "item_unique = df['item'].unique()\n",
    "\n",
    "# 유저, 아티스트 indexing 하는 코드 idx는 index의 약자입니다.\n",
    "user_to_idx = {v:k for k,v in enumerate(user_unique)}\n",
    "idx_to_user = {k:v for k,v in enumerate(user_unique)}\n",
    "item_to_idx = {v:k for k,v in enumerate(item_unique)}\n",
    "idx_to_item = {k:v for k,v in enumerate(item_unique)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:44.124503Z",
     "start_time": "2020-12-11T00:53:33.362053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId column indexing OK!!\n",
      "itemId column indexing OK!!\n"
     ]
    }
   ],
   "source": [
    "# indexing을 통해 데이터 컬럼 내 값을 바꾸는 코드\n",
    "# dictionary 자료형의 get 함수는 https://wikidocs.net/16 을 참고하세요.\n",
    "\n",
    "# user_to_idx.get을 통해 user_id 컬럼의 모든 값을 인덱싱한 Series를 구해 봅시다. \n",
    "# 혹시 정상적으로 인덱싱되지 않은 row가 있다면 인덱스가 NaN이 될 테니 dropna()로 제거합니다. \n",
    "temp_user_data = df['user'].map(user_to_idx.get).dropna()\n",
    "if len(temp_user_data) == len(df):   # 모든 row가 정상적으로 인덱싱되었다면\n",
    "    print('userId column indexing OK!!')\n",
    "    df['user'] = temp_user_data   # data['userId']을 인덱싱된 Series로 교체해 줍니다. \n",
    "else:\n",
    "    print('userId column indexing Fail!!')\n",
    "\n",
    "# movie_to_idx을 통해 artist 컬럼도 동일한 방식으로 인덱싱해 줍니다. \n",
    "temp_item_data = df['item'].map(item_to_idx.get).dropna()\n",
    "if len(temp_item_data) == len(df):\n",
    "    print('itemId column indexing OK!!')\n",
    "    df['item'] = temp_item_data\n",
    "else:\n",
    "    print('itemId column indexing Fail!!')\n",
    "# up_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:53:44.799300Z",
     "start_time": "2020-12-11T00:53:44.125909Z"
    }
   },
   "outputs": [],
   "source": [
    "num_user = df['user'].nunique()\n",
    "num_item = df['item'].nunique()\n",
    "\n",
    "csr_data = csr_matrix((df['rating'], (df.user, df.item)), shape= (num_user, num_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:56:26.713792Z",
     "start_time": "2020-12-11T00:53:44.800672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626b45428e6445a0af048c90fdf6b91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#num_threads=-1\n",
    "als_model = AlternatingLeastSquares(factors=100, regularization=0.01,use_gpu=False,\n",
    "                                    iterations=15,dtype=np.float32,calculate_training_loss=True, num_threads=1)\n",
    "\n",
    "#item x user\n",
    "csr_data_transpose = csr_data.T\n",
    "# csr_data_transpose\n",
    "als_model.fit(csr_data_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:56:33.547927Z",
     "start_time": "2020-12-11T00:56:26.714970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 637911/637911 [00:05<00:00, 120361.15it/s]\n",
      "100%|██████████| 258582/258582 [00:01<00:00, 169331.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "258582"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings_dict = {idx_to_item[i]:tf.convert_to_tensor(als_model.item_factors[i]) for i in tqdm.tqdm(range(num_item))}\n",
    "user_embeddings_dict = {idx_to_user[i]:tf.convert_to_tensor(als_model.user_factors[i]) for i in tqdm.tqdm(range(num_user))}\n",
    "\n",
    "len(user_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T00:56:33.551039Z",
     "start_time": "2020-12-11T00:56:33.548905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637911"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:49:30.737144Z",
     "start_time": "2020-12-11T01:49:26.068818Z"
    }
   },
   "outputs": [],
   "source": [
    "#Getting users with positive rating count greater than 10 \n",
    "# 10 == 'N' positively interacted items\n",
    "# from collections import defaultdict\n",
    "# from collections import Counter\n",
    "users_dict = defaultdict(dict)\n",
    "users_id_list = set()\n",
    "for user_id in users:\n",
    "    rating_freq = Counter(users[user_id][\"rating\"].values)\n",
    "    if rating_freq[4]+rating_freq[5]<10 :\n",
    "        continue    \n",
    "    else:\n",
    "        users_id_list.add(int(user_id))\n",
    "        users_dict[user_id][\"item\"] = users[user_id][\"item\"].values\n",
    "        users_dict[user_id][\"rating\"] = users[user_id][\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:49:31.212212Z",
     "start_time": "2020-12-11T01:49:31.187556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12058627 14680070  7340040 ...  9437172 12058615 11010043]\n"
     ]
    }
   ],
   "source": [
    "users_id_list = np.array(list(users_id_list))\n",
    "print(users_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:04.699179Z",
     "start_time": "2020-12-11T01:55:04.695886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': array([  28067,   41744,   81990,   94755,   95277,  104841,  122183,\n",
      "        177661,  180581,  183115,  211122,  233553,  271914,  284884,\n",
      "        286968,  300146,  339862,  343635,  364176,  364388,  364375,\n",
      "        411644,  445202,  463239,  512989,  632956,  723559,  755129,\n",
      "        809664,  819077,  819739,  878301,  951090, 1009123, 1010557,\n",
      "       1042421, 1071233, 1107949, 1112160, 1125199, 1341839, 1347405,\n",
      "       1487939, 1514645, 1580541, 1928572, 1956531, 1956306, 1962144,\n",
      "       1972774, 1983891, 2009311, 2015798, 2031750, 2098284, 2127133,\n",
      "       2233093, 2285383, 2295964, 2295969, 2295970, 2301303, 2305905,\n",
      "       2388411, 2390438, 2542197,  527007, 2791251,  180670,  199910,\n",
      "        271858,  293239,  441781,  538337,  544191,  766746,  955067,\n",
      "        962416, 1010621, 1025036, 1151374, 1181909, 1889954, 2108769]), 'rating': array([4, 5, 4, 4, 5, 5, 3, 4, 5, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 4, 1, 5,\n",
      "       5, 5, 4, 5, 5, 5, 1, 4, 5, 5, 5, 4, 5, 4, 5, 2, 5, 5, 4, 5, 5, 4,\n",
      "       5, 5, 4, 5, 3, 5, 5, 5, 4, 5, 5, 1, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5,\n",
      "       4, 4, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 4, 1, 5, 5])}\n"
     ]
    }
   ],
   "source": [
    "print(users_dict[12058627])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:05.550025Z",
     "start_time": "2020-12-11T01:55:05.539981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254330"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:06.478935Z",
     "start_time": "2020-12-11T01:55:06.471115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2451206 11306522]\n"
     ]
    }
   ],
   "source": [
    "#choosing default train_test_split of 25%\n",
    "train_users,test_users = train_test_split(users_id_list)\n",
    "print(train_users[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:07.323258Z",
     "start_time": "2020-12-11T01:55:07.319557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7954690 8111429]\n"
     ]
    }
   ],
   "source": [
    "print(test_users[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:07.530601Z",
     "start_time": "2020-12-11T01:55:07.525967Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self,users_list,users_dict):\n",
    "        self.users_list = users_list\n",
    "        self.users_dict = users_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users_list)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        user_id = self.users_list[idx]\n",
    "        items = [('1',)]*10\n",
    "        ratings = [('0',)]*10\n",
    "        j=0\n",
    "        for i,rate in enumerate(self.users_dict[user_id][\"rating\"]):\n",
    "            if int(rate) >3 and j < 10:\n",
    "                items[j] = self.users_dict[user_id][\"item\"][i]\n",
    "                ratings[j] = self.users_dict[user_id][\"rating\"][i]\n",
    "                j += 1\n",
    "        # item = list(self.users_dict[user_id][\"item\"][:])\n",
    "        # rating = list(self.users_dict[user_id][\"rating\"][:])\n",
    "        size = len(items)\n",
    "    \n",
    "        return {'item':items,'rating':ratings,'size':size,'userid':user_id,'idx':idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:07.709698Z",
     "start_time": "2020-12-11T01:55:07.707818Z"
    }
   },
   "outputs": [],
   "source": [
    "train_users_dataset = UserDataset(train_users,users_dict)\n",
    "test_users_dataset = UserDataset(test_users,users_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:07.866212Z",
     "start_time": "2020-12-11T01:55:07.864248Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_users_dataset, batch_size=1)\n",
    "test_dataloader = DataLoader(test_users_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:08.006019Z",
     "start_time": "2020-12-11T01:55:08.003977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190747\n"
     ]
    }
   ],
   "source": [
    "train_num = len(train_dataloader)\n",
    "print(train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:08.160635Z",
     "start_time": "2020-12-11T01:55:08.158681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63583\n"
     ]
    }
   ],
   "source": [
    "test_num = len(test_dataloader)\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. State Representation Models¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR-ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:08.526962Z",
     "start_time": "2020-12-11T01:55:08.522227Z"
    }
   },
   "outputs": [],
   "source": [
    "''' input\n",
    "    # dataloader에서 나온 return들\n",
    "    # user_idb : 해당 user의 id \n",
    "    # itemb : 유저가 rating 한 item id 10개(tensor))\n",
    "    # memory :  유저가 rating 한 item들 list 크기는 유저 * 10(item)  \n",
    "    idx : user_list에서 user의 index\n",
    "    output\n",
    "    state : #state tensor shape [21,100]\n",
    "'''\n",
    "def drrave_state_rep(userid_b,items,memory,idx):\n",
    "    user_num = idx\n",
    "    H = [] #item embeddings\n",
    "    user_n_items = items\n",
    "    user_embeddings = torch.Tensor(np.array(user_embeddings_dict[int(userid_b[0])]),).unsqueeze(0)\n",
    "    for i,item in enumerate(user_n_items):\n",
    "        H.append(np.array(item_embeddings_dict[int(item[0])]))\n",
    "    avg_layer = nn.AvgPool1d(1)  # pooling layer 사용 \n",
    "    item_embeddings = avg_layer(torch.Tensor(H,).unsqueeze(0)).permute(0,2,1).squeeze(0)\n",
    "    #print('item_embedding.size: ', item_embeddings.size())\n",
    "    #print('item_embedding_no permute: ', item_embeddings)\n",
    "    #print('item_embedding_no permute_T: ', item_embeddings.T)\n",
    "    #item_embeddings_permute = avg_layer(torch.Tensor(H,).unsqueeze(0)).permute(0,2,1).squeeze(0)\n",
    "    #print('item_embedding_permute: ', item_embeddings)\n",
    "    #print('item_embedding.size: ', item_embeddings.size()) \n",
    "    #print(item_embeddings)\n",
    "    #assert (item_embeddings == item_embeddings_permute.T).any()\n",
    "    state = torch.cat([user_embeddings,user_embeddings*item_embeddings.T,item_embeddings.T])\n",
    "    #print('state.size: ', state.size())\n",
    "    #print('user_embedding.size: ', user_embeddings.size())\n",
    "    # permute => transpose\n",
    "    return state #state tensor shape [21,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRR-u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:08.771891Z",
     "start_time": "2020-12-11T01:55:08.770312Z"
    }
   },
   "outputs": [],
   "source": [
    "# def drru_state_rep(userid_b,items,memory,idx):\n",
    "#     user_num = idx\n",
    "#     H = []\n",
    "#     user_n_items = items\n",
    "#     user_embeddings = user_embeddings_dict[userid_b[0]]\n",
    "#     for i,item in enumerate(user_n_items):\n",
    "#         ui = np.array(user_embeddings) * np.array(movie_embeddings_dict[item[0]])\n",
    "#         H.append(ui)\n",
    "\n",
    "#     pairs = list(itertools.combinations(memory[user_num], 2))\n",
    "#     for item1,item2 in pairs:\n",
    "#         pair1 =  np.array(movie_embeddings_dict[str(int(item1))])\n",
    "#         pair2 = np.array(movie_embeddings_dict[str(int(item2))])\n",
    "\n",
    "#         product = pair1*pair2\n",
    "#         H.append(product)\n",
    "#     state = torch.Tensor(H,)\n",
    "#     return state #state tensor shape [55,100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRR-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:09.015721Z",
     "start_time": "2020-12-11T01:55:09.013893Z"
    }
   },
   "outputs": [],
   "source": [
    "# def drrp_state_rep(items,memory,idx):\n",
    "#   user_num = idx\n",
    "#   H = []\n",
    "#   user_n_items = items\n",
    "#   for i,item in enumerate(user_n_items):\n",
    "#     H.append(np.array(movie_embeddings_dict[item[0]]))\n",
    "  \n",
    "#   pairs = list(itertools.combinations(memory[user_num], 2))\n",
    "#   for item1,item2 in pairs:\n",
    "#     pair1 =  np.array(movie_embeddings_dict[str(int(item1))])\n",
    "#     pair2 = np.array(movie_embeddings_dict[str(int(item2))])\n",
    "#     product = pair1*pair2\n",
    "#     H.append(product)\n",
    "#   state = torch.Tensor(H,)\n",
    "#   return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state-rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:09.289202Z",
     "start_time": "2020-12-11T01:55:09.286535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef state_rep(item_b):\\n    state = []\\n    user_embeddings = np.zeros((len(columns),100))\\n    item_ids = list(item[0] for item in item_b)\\n    for i,subitem in enumerate(user_embeddings):\\n        if idx_to_id[i] in item_ids:\\n            user_embeddings[i] = np.array(item_embeddings_dict[idx_to_id[i]])\\n        else:\\n            user_embeddings[i] = np.zeros((100,))\\n    state = torch.Tensor(user_embeddings,)\\n    return torch.reshape(state,[-1]) \\n'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just n items and their embeddings used to represent state\n",
    "'''\n",
    "def state_rep(item_b):\n",
    "    state = []\n",
    "    user_embeddings = np.zeros((len(columns),100))\n",
    "    item_ids = list(item[0] for item in item_b)\n",
    "    for i,subitem in enumerate(user_embeddings):\n",
    "        if idx_to_id[i] in item_ids:\n",
    "            user_embeddings[i] = np.array(item_embeddings_dict[idx_to_id[i]])\n",
    "        else:\n",
    "            user_embeddings[i] = np.zeros((100,))\n",
    "    state = torch.Tensor(user_embeddings,)\n",
    "    return torch.reshape(state,[-1]) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Actor, Critic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.319158Z",
     "start_time": "2020-12-11T01:55:09.624768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pabloppp/pytorch-tools@0.2.4\n",
      "  Cloning https://github.com/pabloppp/pytorch-tools (to revision 0.2.4) to /tmp/pip-req-build-ype1p7r_\n",
      "  Running command git clone -q https://github.com/pabloppp/pytorch-tools /tmp/pip-req-build-ype1p7r_\n",
      "  Running command git checkout -q 86c73996537002ab29e7e40f925cb90756f58156\n",
      "Requirement already satisfied, skipping upgrade: torch==1.* in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torchtools==0.2.4) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: torchvision in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torchtools==0.2.4) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy==1.* in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torchtools==0.2.4) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torch==1.*->torchtools==0.2.4) (0.6)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torch==1.*->torchtools==0.2.4) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: future in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torch==1.*->torchtools==0.2.4) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (from torchvision->torchtools==0.2.4) (7.0.0)\n",
      "Building wheels for collected packages: torchtools\n",
      "  Building wheel for torchtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchtools: filename=torchtools-0.2.4-py3-none-any.whl size=19202 sha256=4972618685fa3472d58691e6359bfa8e93a4a2ff372fd88331730efe97a16645\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wvxhhs3r/wheels/e9/db/08/ceb66f88d5c31d39af6901601b4b9084b365c3b484105ee2f5\n",
      "Successfully built torchtools\n",
      "Installing collected packages: torchtools\n",
      "  Attempting uninstall: torchtools\n",
      "    Found existing installation: torchtools 0.2.4\n",
      "    Uninstalling torchtools-0.2.4:\n",
      "      Successfully uninstalled torchtools-0.2.4\n",
      "Successfully installed torchtools-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pabloppp/pytorch-tools@0.2.4 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.324893Z",
     "start_time": "2020-12-11T01:55:13.320417Z"
    }
   },
   "outputs": [],
   "source": [
    "#Actor Model:\n",
    "#Generating an action a based on state s\n",
    "\n",
    "# Input_dim 5500, output_dim 100, hidden_dim 256 for drr-u, p\n",
    "# Input_dim 2100, output_dim 100, hidden_dim 256 for drr-ave\n",
    "\n",
    "# embedding을 normalize(-1, 1) => tanh\n",
    "# embedding을 standard scaling => PCA whitening\n",
    "\n",
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,hidden_dim):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.drop_layer = nn.Dropout(p=0.5)        \n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        # print(x.shape)\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        # print(x.shape)\n",
    "        x = self.drop_layer(x)\n",
    "        # x = torch.tanh(self.linear3(x)) # in case embeds are -1 1 normalized\n",
    "        x = self.linear3(x) # in case embeds are standard scaled / wiped using PCA whitening\n",
    "        # return state, x\n",
    "        return x # state = self.state_rep(state)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.362147Z",
     "start_time": "2020-12-11T01:55:13.326002Z"
    }
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim,hidden_dim):\n",
    "\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.drop_layer = nn.Dropout(p=0.5)\n",
    "    \n",
    "        self.linear1 = nn.Linear(input_dim + output_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self,state,action):    \n",
    "        x = torch.cat([state, action], 1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.372824Z",
     "start_time": "2020-12-11T01:55:13.363103Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        #self.buffer = [0 for _ in range(capacity)]\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        # print(batch)\n",
    "        '''\n",
    "        zip:\n",
    "        (s1, a1, r1, ns1) (s2, a2, r2, ns2) (s3, a3, r3, ns3)\n",
    "        => (s1, s2, s3), (a1, a2, a3), (r1, r2, r3)\n",
    "        '''\n",
    "        state, action, reward, next_state = map(np.stack,zip(*batch))\n",
    "        return state, action, reward, next_state\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.398552Z",
     "start_time": "2020-12-11T01:55:13.374234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstate = drrave_state_rep(userid_b,item_b,memory,idx_b)\\nstate_rep =  torch.reshape(state,[-1])\\nnext_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\\nnext_state_rep = torch.reshape(next_state,[-1])\\n#R.push(state_rep.detach().cpu().numpy(), action_emb.detach().cpu().numpy(), reward, next_state_rep.detach().cpu().numpy()\\n)\\n'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "state_rep =  torch.reshape(state,[-1])\n",
    "next_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "next_state_rep = torch.reshape(next_state,[-1])\n",
    "#R.push(state_rep.detach().cpu().numpy(), action_emb.detach().cpu().numpy(), reward, next_state_rep.detach().cpu().numpy()\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.425094Z",
     "start_time": "2020-12-11T01:55:13.399459Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "# cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.441874Z",
     "start_time": "2020-12-11T01:55:13.425877Z"
    }
   },
   "outputs": [],
   "source": [
    "#used for plotting purposes\n",
    "p_loss = []\n",
    "v_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.453068Z",
     "start_time": "2020-12-11T01:55:13.443030Z"
    }
   },
   "outputs": [],
   "source": [
    "def ddpg_update(batch_size=1, \n",
    "                gamma = 0.6,\n",
    "                min_value=-np.inf,\n",
    "                max_value=np.inf,\n",
    "                soft_tau=1e-2):\n",
    "    \n",
    "    state, action, reward, next_state = replay_buffer.sample(batch_size)\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).to(device)\n",
    "    # print(state.shape)\n",
    "    # print(policy_net(state).shape)\n",
    "    policy_loss = value_net(state, policy_net(state))\n",
    "    policy_loss = -policy_loss.mean()\n",
    "    p_loss.append(policy_loss)\n",
    "    next_action    = target_policy_net(next_state)\n",
    "    target_value   = target_value_net(next_state, next_action.detach())\n",
    "    expected_value = reward + gamma * target_value\n",
    "    expected_value = torch.clamp(expected_value, min_value, max_value)\n",
    "\n",
    "    value = value_net(state, action)\n",
    "    # print(\"1\")\n",
    "    value_loss = value_criterion(value, expected_value.detach())\n",
    "    # print(\"2\")\n",
    "    v_loss.append(value_loss)\n",
    "    policy_optimizer.zero_grad()\n",
    "    # print(\"3\")\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "                target_param.data.copy_(\n",
    "                    target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "                )\n",
    "\n",
    "    for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.499173Z",
     "start_time": "2020-12-11T01:55:13.453995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n"
     ]
    }
   ],
   "source": [
    "#initializing actor and critic networks for drru and drrp state representation\n",
    "\n",
    "value_net = Critic(5500,100,256)\n",
    "policy_net = Actor(5500,100,256)\n",
    "\n",
    "target_value_net = Critic(5500,100,256)\n",
    "target_policy_net = Actor(5500,100,256)\n",
    "\n",
    "    \n",
    "target_policy_net.eval()\n",
    "target_value_net.eval()\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "value_criterion = nn.MSELoss()\n",
    "value_optimizer      = Ranger(value_net.parameters(),  lr=1e-4)\n",
    "policy_optimizer     = Ranger(policy_net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.524198Z",
     "start_time": "2020-12-11T01:55:13.500374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n"
     ]
    }
   ],
   "source": [
    "#initializing for drrave state representation\n",
    "\n",
    "value_net = Critic(2100,100,256)\n",
    "policy_net = Actor(2100,100,256)\n",
    "\n",
    "target_value_net = Critic(2100,100,256)\n",
    "target_policy_net = Actor(2100,100,256)\n",
    "\n",
    "\n",
    "target_policy_net.eval()\n",
    "target_value_net.eval()\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "value_criterion = nn.MSELoss()\n",
    "value_optimizer      = Ranger(value_net.parameters(),  lr=1e-4)\n",
    "policy_optimizer     = Ranger(policy_net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.527286Z",
     "start_time": "2020-12-11T01:55:13.525156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
      "  (linear1): Linear(in_features=2100, out_features=256, bias=True)\n",
      "  (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (linear3): Linear(in_features=256, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(policy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:13.614035Z",
     "start_time": "2020-12-11T01:55:13.608997Z"
    }
   },
   "outputs": [],
   "source": [
    "replay_buffer_size = 10000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)\n",
    "\n",
    "memory = np.ones((train_num,10))*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:14.786678Z",
     "start_time": "2020-12-11T01:55:14.784692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13018882\n"
     ]
    }
   ],
   "source": [
    "print(int(userid_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:15.145411Z",
     "start_time": "2020-12-11T01:55:15.142816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13018882\n"
     ]
    }
   ],
   "source": [
    "print(int(userid_b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:15.395754Z",
     "start_time": "2020-12-11T01:55:15.391007Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_action(state,action_emb,userid_b,item_b,preds):\n",
    "    action_emb = torch.reshape(action_emb,[1,100]).unsqueeze(0)\n",
    "    item_embedding = []\n",
    "    for item in users_dict[int(userid_b[0])][\"item\"]:  \n",
    "        item_embedding.append(np.array(item_embeddings_dict[item]))\n",
    "    item_embedding = torch.Tensor(item_embedding,)\n",
    "    items = item_embedding.T.unsqueeze(0)\n",
    "    m = torch.bmm(action_emb,items).squeeze(0)  #torch.bmm : batch 행렬 곱연산\n",
    "    sorted_m,indices = torch.sort(m,descending=True)\n",
    "    index_list = list(indices[0])\n",
    "    for i in index_list:\n",
    "        if users_dict[int(userid_b[0])][\"item\"][i] not in preds:    \n",
    "            preds.add(users_dict[int(userid_b[0])][\"item\"][i])\n",
    "            return int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:15.708617Z",
     "start_time": "2020-12-11T01:55:15.706678Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_memory(memory,action,idx):\n",
    "    memory[idx] = list(memory[idx,1:])+[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:15.993852Z",
     "start_time": "2020-12-11T01:55:15.992077Z"
    }
   },
   "outputs": [],
   "source": [
    "rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:16.263412Z",
     "start_time": "2020-12-11T01:55:16.259316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([358005]), tensor([1119101]), tensor([1119100]), tensor([1213496]), tensor([1234186]), tensor([1475547]), tensor([1516420]), tensor([1531819]), tensor([1583324]), tensor([1590874])]\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "first = next(it)\n",
    "item_b,rating_b,size_b,userid_b,idx_b = first['item'],first['rating'],first['size'],first['userid'],first['idx']\n",
    "print(item_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:17.068465Z",
     "start_time": "2020-12-11T01:55:17.066142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451206\n"
     ]
    }
   ],
   "source": [
    "print(int(userid_b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:17.365820Z",
     "start_time": "2020-12-11T01:55:17.359048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8839e-02, -1.5145e-02,  2.2790e-02,  ..., -2.6837e-02,\n",
       "         -2.6505e-02,  1.6536e-02],\n",
       "        [-1.4350e-03, -3.8199e-04,  4.9297e-04,  ..., -2.3018e-04,\n",
       "          4.8701e-04,  4.5806e-05],\n",
       "        [ 1.7270e-03,  2.1298e-04,  5.5947e-04,  ...,  4.2160e-04,\n",
       "          5.2081e-04,  1.7858e-04],\n",
       "        ...,\n",
       "        [-4.5548e-02, -1.8985e-02,  2.3134e-02,  ..., -1.4004e-02,\n",
       "         -1.7929e-02,  1.3950e-02],\n",
       "        [-8.2578e-03, -6.1441e-02,  5.7845e-02,  ..., -1.8318e-02,\n",
       "         -2.1500e-02,  3.8543e-02],\n",
       "        [-2.0690e-02, -6.5793e-03,  1.8345e-02,  ..., -7.8332e-03,\n",
       "         -1.0332e-02,  8.6556e-04]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = np.ones((train_num,10))*-1\n",
    "drrave_state_rep(userid_b,item_b,memory,idx_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:17.563451Z",
     "start_time": "2020-12-11T01:55:17.560788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1119101])\n"
     ]
    }
   ],
   "source": [
    "print(item_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:17.831067Z",
     "start_time": "2020-12-11T01:55:17.824602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 358005. 1119101. 1119100. 1213496. 1234186. 1475547. 1516420. 1531819.\n",
      " 1583324. 1590874.]\n"
     ]
    }
   ],
   "source": [
    "memory = np.ones((train_num,10))*-1\n",
    "memory[idx_b] = [item[0] for item in item_b]\n",
    "print(memory[idx_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:18.121812Z",
     "start_time": "2020-12-11T01:55:18.119515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1119101)\n"
     ]
    }
   ],
   "source": [
    "print(item_b[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:18.544607Z",
     "start_time": "2020-12-11T01:55:18.541854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.580050e+05  1.119101e+06  1.119100e+06 ...  1.531819e+06\n",
      "   1.583324e+06  1.590874e+06]\n",
      " [-1.000000e+00 -1.000000e+00 -1.000000e+00 ... -1.000000e+00\n",
      "  -1.000000e+00 -1.000000e+00]\n",
      " [-1.000000e+00 -1.000000e+00 -1.000000e+00 ... -1.000000e+00\n",
      "  -1.000000e+00 -1.000000e+00]\n",
      " ...\n",
      " [-1.000000e+00 -1.000000e+00 -1.000000e+00 ... -1.000000e+00\n",
      "  -1.000000e+00 -1.000000e+00]\n",
      " [-1.000000e+00 -1.000000e+00 -1.000000e+00 ... -1.000000e+00\n",
      "  -1.000000e+00 -1.000000e+00]\n",
      " [-1.000000e+00 -1.000000e+00 -1.000000e+00 ... -1.000000e+00\n",
      "  -1.000000e+00 -1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:55:19.220192Z",
     "start_time": "2020-12-11T01:55:19.217639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print(idx_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-11T01:55:20.117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5821/190746 [06:00<3:21:25, 15.30it/s]"
     ]
    }
   ],
   "source": [
    "preddict = dict()\n",
    "it = iter(train_dataloader)\n",
    "for episode in tqdm.tqdm(range(train_num-1)):    \n",
    "    batch_size= 1\n",
    "    preds = set()\n",
    "    first = next(it)\n",
    "    item_b,rating_b,size_b,userid_b,idx_b = first['item'],first['rating'],first['size'],first['userid'],first['idx']\n",
    "    memory[idx_b] = [item[0] for item in item_b]\n",
    "    state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "    for j in range(5):    \n",
    "        state_rep =  torch.reshape(state,[-1])\n",
    "        action_emb = policy_net(state_rep)\n",
    "        action = get_action(state,action_emb,userid_b,item_b,preds)\n",
    "        rate = int(users_dict[int(userid_b[0])][\"rating\"][action])\n",
    "        try:\n",
    "            ratings = (int(rate)-3)/2\n",
    "        except:\n",
    "            ratings = 0\n",
    "        reward = torch.Tensor((ratings,))\n",
    "\n",
    "        if reward > 0:\n",
    "            update_memory(memory,int(users_dict[int(userid_b[0])][\"item\"][action]), idx_b)\n",
    "\n",
    "        next_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "        next_state_rep = torch.reshape(next_state,[-1])\n",
    "        replay_buffer.push(state_rep.detach().cpu().numpy(), action_emb.detach().cpu().numpy(), reward, next_state_rep.detach().cpu().numpy())\n",
    "        if len(replay_buffer) > batch_size:\n",
    "            ddpg_update()\n",
    "\n",
    "        state = next_state\n",
    "    preddict[userid_b[0]] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:44:35.231209Z",
     "start_time": "2020-12-11T01:44:35.133125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe57afe9bd0>]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:44:35.515266Z",
     "start_time": "2020-12-11T01:44:35.430641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe8a9acd790>]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(p_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T01:03:34.183968Z",
     "start_time": "2020-12-11T01:03:34.147087Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_pred_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-30de617b82c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_embed_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtest_embed_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embed_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-30de617b82c0>\u001b[0m in \u001b[0;36mget_cosine_sim\u001b[0;34m(userid)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cosine_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"item\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_pred_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#Getting Cosine similarity of recommended items for a particular userid that has been evaluated\n",
    "# from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "# import seaborn as sns\n",
    "\n",
    "def get_cosine_sim(userid):\n",
    "    test_pred = test_pred_dict[userid]\n",
    "    for i,item in enumerate(users_dict[userid][\"item\"]):\n",
    "        if item in test_pred:\n",
    "            print(item,\":\",users_dict[userid][\"rating\"][i])\n",
    "\n",
    "    test_embed = []\n",
    "    for item in test_pred:\n",
    "        test_embed.append(np.array(item_embeddings_dict[int(item)]))\n",
    "\n",
    "    test_embed_array = np.array(test_embed)\n",
    "\n",
    "    return test_embed_array\n",
    "\n",
    "test_embed_array = get_cosine_sim(userid_b[0])\n",
    "ax = sns.heatmap(cs(test_embed_array), linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.281895Z",
     "start_time": "2020-12-10T06:50:46.481Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction algorithm\n",
    "it2 = iter(test_dataloader)\n",
    "precision = 0\n",
    "test_pred_dict = dict()\n",
    "for j in range(len(test_dataloader)-1):  #session 돌리기 : timestamps 내에서 items들 \n",
    "    first = next(it2)\n",
    "    item_b,rating_b,size_b,userid_b,idx_b = first['item'],first['rating'],first['size'],first['userid'],first['idx']\n",
    "    memory[idx_b] = [item[0] for item in item_b]\n",
    "    state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "    count = 0\n",
    "    test_pred = set()\n",
    "    for j in range(5):  #policy network5번 돌리기 , 추천 5번 하기\n",
    "        state_rep =  torch.reshape(state,[-1])\n",
    "        action_emb = policy_net(state_rep)   # policy_net = actor : items들의 선호도 (rating)\n",
    "        action = get_action(state,action_emb,userid_b,item_b,test_pred)\n",
    "        rate = int(users_dict[userid_b[0]][\"rating\"][action])\n",
    "        try:\n",
    "            rating = (int(rate)-3)/2\n",
    "        except:\n",
    "            rating = 0\n",
    "        reward = torch.Tensor((rating,))\n",
    "\n",
    "        if reward > 0:\n",
    "            count += 1\n",
    "            update_memory(memory,int(users_dict[userid_b[0]][\"item\"][action]),idx_b)\n",
    "        next_state = drrave_state_rep(userid_b,item_b,memory,idx_b)\n",
    "        state = next_state\n",
    "    precision += count/5\n",
    "    test_pred_dict[userid_b[0]] = test_pred\n",
    "print(\"p\",precision/(len(test_dataloader)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.282584Z",
     "start_time": "2020-12-10T06:50:46.482Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = '/content/gdrive/My Drive/RLProject/Models/drravepolicy_net.pth'\n",
    "torch.save(policy_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.283124Z",
     "start_time": "2020-12-10T06:50:46.484Z"
    }
   },
   "outputs": [],
   "source": [
    "value_PATH = '/content/gdrive/My Drive/RLProject/Models/drravevalue_net.pth'\n",
    "torch.save(value_net.state_dict(), value_PATH)\n",
    "\n",
    "tpolicy_PATH = '/content/gdrive/My Drive/RLProject/Models/drravetpolicy_net.pth'\n",
    "torch.save(target_policy_net.state_dict(), tpolicy_PATH)\n",
    "\n",
    "tvalue_PATH = '/content/gdrive/My Drive/RLProject/Models/drravetvalue_net.pth'\n",
    "torch.save(target_value_net.state_dict(), tvalue_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.283811Z",
     "start_time": "2020-12-10T06:50:46.485Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('/content/gdrive/My Drive/RLProject/Models/train_dataloader',train_dataloader)\n",
    "np.save('/content/gdrive/My Drive/RLProject/Models/test_dataloader',test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.284614Z",
     "start_time": "2020-12-10T06:50:46.487Z"
    }
   },
   "outputs": [],
   "source": [
    "policy_net = Actor(5500,100,256)\n",
    "policy_net.load_state_dict(torch.load(PATH))\n",
    "policy_net.eval()\n",
    "\n",
    "value_net = Critic(5500,100,256)\n",
    "value_net.load_state_dict(torch.load(value_PATH))\n",
    "value_net.eval()\n",
    "\n",
    "target_policy_net = Actor(5500,100,256)\n",
    "target_policy_net.load_state_dict(torch.load(tpolicy_PATH))\n",
    "target_policy_net.eval()\n",
    "\n",
    "target_value_net = Critic(5500,100,256)\n",
    "target_value_net.load_state_dict(torch.load(tvalue_PATH))\n",
    "target_value_net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.285220Z",
     "start_time": "2020-12-10T06:50:46.488Z"
    }
   },
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "train_data = np.load('/content/gdrive/My Drive/RLProject/Models/train_users.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T06:50:48.285755Z",
     "start_time": "2020-12-10T06:50:46.488Z"
    }
   },
   "outputs": [],
   "source": [
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
